<html>
<head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" >
<title>Java API Tutorial for AllegroGraph</title>

<style type="text/css">

.input { margin-left:4em; background-color:#ADDFFF;}
.output { margin-left:4em; background-color:#F1F1F1;}
.returnlink {font-size:small;  font-weight:normal; }
</style>
</head>
<body>

<h1>Java Sesame API Tutorial for AllegroGraph</h1>
<p>This is an introduction to the Java client API to the AllegroGraph RDFStore&#8482; from <a href="http://agraph.franz.com/allegrograph/">Franz Inc.</a> </p>
<p>
The Java Sesame API offers convenient and efficient
access to an AllegroGraph server from a Java-based application.  This API provides methods for
creating, querying and maintaining RDF data, and for managing the stored triples. </p>
<p>The Java Sesame API emulates the Eclipse RDF4J (formerly known as Aduna Sesame) API to make it easier to migrate from RDF4J to AllegroGraph.&nbsp; &nbsp; </p>
<h2 id="Contents">Contents</h2>
<table width="554" border="0" style="vertical-align:top" >
  <tr>
    <td width="249"><ul>
      <li><a href="#Overview">Overview</a></li>
<!--      <li><a href="#PrerequisitesWindows">Prerequisites (Windows)</a> </li>
-->      <li><a href="#PrerequisitesLinux">Prerequisites (Linux)</a></li>
      <li><a href="#Terminology">Terminology</a></li>
	  <li><a href="#Creating Users with WebView">Creating Users with WebView</a></li>
      <li><a href="#Creating a Repository">Creating a Repository and Triple Indices</a></li>
      <li><a href="#Asserting and Retracting Triples">Asserting and Retracting Triples</a></li>
      <li><a href="#A SPARQL Query">A SPARQL Query</a></li>
      <li><a href="#Statement Matching">Statement Matching</a></li>
      <li><a href="#Literal Values">Literal Values</a></li>
      <li><a href="#Importing Triples">Importing Triples</a></li>
	  <li><a href="#Exporting Triples">Exporting Triples</a></li>      
      <li><a href="#Datasets and Contexts">Searching Multiple Graphs</a></li>
      <li><a href="#Namespaces">Namespaces</a></li>
    </ul></td>
    <td width="295"><ul>
      <li><a href="#Free Text Search">Free Text Search</a></li>
      <li><a href="#Ask, Describe, Construct and Update Queries">Ask, Describe, Construct, and Update Queries</a></li>
      <li><a href="#Parametric Queries">Parametric Queries</a></li>
      <li><a href="#Range Matches">Range Matches</a></li>
      <li><a href="#Federated Repositories">Federated Repositories</a></li>  
	  <li><a href="#Prolog Rule Queries">Prolog Rule Queries</a></li>
      <li><a href="#Loading Prolog Rules">Loading Prolog Rules</a> </li>
      <li><a href="#RDFS++ Inference">RDFS++ Inference</a> </li>
      <li><a href="#Geospatial Search">Geospatial Search</a> </li>
      <li><a href="#Social Network Analysis">Social Network Analysis</a> </li>
      <li><a href="#Transaction">Transactions </a></li>
      <li><a href="#Duplicate Triples">Duplicate Triples</a> </li>
    </ul>
    <p>&nbsp;</p></td>
  </tr>
</table>
<p>&nbsp;</p>
<h2 id="Overview">Overview&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>The Java client tutorial rests on a simple architecture involving AllegroGraph, disk-based data files, Java, and a file of Java examples called TutorialExamples.java.</p>
<table width="964" border="0">
  <tr>
    <td width="286"><p>The AllegroGraph Java client distribution contains the Java Sesame API. </p>
    <p>The Java client communicates with the AllegroGraph Server through HTTP port 10035 in this tutorial. Java and AllegroGraph may be installed on the same computer, but in practice one server is shared by multiple clients running on different machines. </p>
    <p>Load TutorialExamples.java into Java to view the tutorial examples. </p></td>
    <td width="668"><img src="allegrographdiagramJava.jpg" width="668" height="443"></td>
  </tr>
</table>
<p>Each lesson in <strong>TutorialExamples.java</strong> is encapsulated in a Java method, named exampleN(), where N ranges from 0 to 21 (or more). The function names are referenced in the title of each section to make it easier to compare the tutorial text and the living code of the examples file. </p>
<h2 id="PrerequisitesLinux">Prerequisites (Linux) &nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>The tutorial examples can be run on a Linux system, running AllegroGraph and the examples on the same computer ("localhost"). The tutorial assumes that AllegroGraph has been installed and configured using the procedure posted on <a href="http://www.franz.com/agraph/support/documentation/current/server-installation.html">this webpage</a>. </p>
<h2 id="Terminology">Terminology&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>We need to clarify some terminology before proceeding. </p>
<ul>
  <li>"RDF" is the <a href="http://www.w3.org/RDF/">Resource Description Framework</a> defined by the <a href="http://www.w3.org/">World Wide Web Consortium</a> (W3C). It provides an elegantly simple means for describing multi-faceted resource objects and for linking them into complex relationship graphs. AllegroGraph Server creates, searches, and manages such RDF graphs. </li>
  <li>A "URI" is a <a href="http://www.ietf.org/rfc/rfc2396.txt">Uniform Resource Identifier</a>. It is a label used to uniquely identify various types of entities in an RDF graph. A typical URI looks a lot like a web address: http://example.org/project/class#number. In spite of the resemblance, a URI is not a web address. It is simply a unique label. </li>
  <li>A "triple" is a data statement, a "fact," stored in RDF format. It states that a  resource has an attribute with a value. It consists of three fields:</li>
  <ul>  <li>Subject: The first field contains the URI that uniquely identifies the resource that this triple describes. </li>
  <li>Predicate: The second field contains the URI identifying a property of this resource, such as its color or size, or a relationship between this resource and another one, such as parentage or ownership. </li>
  <li>Object: The third field is the value of the property. It could be a literal value, such as "red," or the URI of a linked resource. </li>
  </ul>
  <li>A "quad" is a triple with an added "context" field, which is used to divide the repository into "subgraphs." This context or subgraph is just a URI label that appears in the fourth field of related triples. </li>
  <li>A "quint" is a quad with a fifth field used for the "tripleID." AllegroGraph Server implements all triples as quints behind the scenes. The fourth and fifth fields are often ignored, however, so we speak casually of "triples," and sometimes of "quads," when it would be more rigorous to call them all "quints." </li>
  <li>A "resource description" is defined as a collection of triples that all have the same URI in the subject field. In other words, the triples all describe attributes of the same thing.</li>
  <li>A "statement" is a client-side Java object that describes a triple (quad, quint).&nbsp; </li>
</ul>
  <table width="809" border="0">
  <tr>
    <td width="378"><p>In the context of AllegroGraph Server: </p>
      <ul>
        <li>A "catalog" is a list of repositories owned by an AllegroGraph server.</li>
        <li>A "repository" is a collection of triples within a Catalog, stored and indexed on a hard disk.</li>
        <li>A "context" is a subgraph of the triples in a repository. </li>
        <li>If contexts are not in use, the triples are stored in the background (default) graph. </li>
      </ul>      </td>
    <td width="421"><img src="catalogrepositorycontext.jpg" width="397" height="400" align="right"></td>
  </tr>
</table>
  <h2 id="Creating Users with WebView">Creating Users with WebView &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
  <p>Each connection to an AllegroGraph server runs under the credentials of a registered AllegroGraph user account. </p>
  <h3>Initial Superuser Account </h3>
  <p>The installation instructions for AllegroGraph advise you to create a default <strong>superuser</strong> called "test", with password "xyzzy". This is the user (and password) expected by the tutorial examples. If you created this account as directed, you can proceed to the <a href="#Creating a Repository">next section</a> and return to this topic at a later time when you need to create non-superuser accounts. </p>
  <p>If you created a different superuser account you'll have to edit the <strong>TutorialExamples.java</strong> file before proceeding. Modify these entries near the top of the file:</p>
  <pre class="input">    static private final String USERNAME = "test";<br>    static private final String PASSWORD = "xyzzy";</pre>
  <p>Otherwise you'll get an authentication failure when you attempt to connect to the server. </p>
  <h3>Users, Permissions, Access Rules, and Roles</h3>
  <p>AllegroGraph user accounts may be given any combination of the following three permissions:</p>
  <ul>
    <li>Superuser</li>
    <li>Start Session</li>
    <li>Evaluate Arbitrary Code</li>
  </ul>
  <p>In addition, a user account may be given read, write or read/write access to individual repositories. </p>
  <p>You can also define a <strong>role</strong> (such as "librarian") and give the role a set of permissions and access rules. Then you can assign several users to a shared role. This lets you manage their permissions and access by editing the role instead of the individual user accounts. </p>
  <p>A <strong>superuser</strong> automatically has all possible permissions and unlimited access. A superuser can also create, manage and delete other user accounts. Non-superusers cannot view or edit account settings. </p>
  <p>A user with the <strong>Start Sessions</strong> permission can use the AllegroGraph features that require spawning a dedicated session, such as <a href="#Transaction">Transactions </a> and <a href="#Social Network Analysis">Social Network Analysis</a>. If you try to use these features without the appropriate permission, you'll encounter authentication errors. </p>
  <p>A user with permission to <strong>Evaluate Arbitrary Code </strong>can run <a href="#Prolog Rule Queries">Prolog Rule Queries</a>. 


  This user can also do anything else that allows executing Lisp code, such as defining select-style generators, or doing eval-in-server, as well as loading server-side files. </p>
  <h3>WebView</h3>
  <p>WebView is AllegroGraph's HTTP-based graphical user interface for user and repository management.  It provides a SPARQL endpoint for querying your triple stores as well as various tools that let you create and maintain triple stores interactively. </p>
  <p>To connect to WebView, simply direct your Web browser to the AllegroGraph port of your server. If you have installed AllegroGraph locally (and used the default port number), use:</p>
  <pre class="output">http://localhost:10035</pre>
  <p>You will be asked to log in. Use the superuser credentials described in the previous section. </p>
  <p>The first page of WebView is a summary of your catalogs, repositories, and federations. Click the <strong>user account</strong> link in the lower left corner of the page. This exposes the <strong>Users and Roles</strong> page.</p>
  <p><img src="webviewUser1.jpg" width="668" height="340"> </p>
  <p>This is the environment for creating and managing user accounts. </p>
  <p>To create a new user, click the [add a user] link. This exposes a small form where you can enter the username (one symbol) and password. Click OK to save the new account.</p>
  <p>The new user will appear in the list of users. Click the [view permissions] link to open a control panel for the new user account:</p>
  <p><img src="webviewNewUser.jpg" width="658" height="171"> </p>
  <p>Use the checkboxes to apply permissions to this account (superuser, start session, evaluate arbitrary code). </p>
  <p>It is important that you set up access permissions for the new user. Use the form to create an access rule by selecting read, write or read/write access, naming a catalog (or * for all), and naming a repository within that catalog (or * for all). Click the [add] link. This creates an access rule for your new user. The access rule will appear in the permissions display:</p>
  <p><img src="webviewAccessRule.jpg" width="629" height="196"> </p>
  <p>This new user can log in and perform transactions on any repository in the system. </p>
  <p>To repeat, the "test" superuser is all you need to run all of the tutorial examples. This section is for the day when you want to issue more modest credentials to some of your operators. </p>
  <h2 id="Creating a Repository">Creating a Repository and Triple Indices (example1()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
  <p>The first task is to start our AllegroGraph Server and open a repository. This task is implemented in<strong> example1()</strong> from<strong> TutorialExamples.java</strong>. </p>
<p>In <strong>example1()</strong> we build a chain of Java objects,  ending in a "connection" object that lets us manipulate triples in a specific repository. The overall process of generating the connection object follows 
this diagram:</p>
  <table width="809" border="0">
  <tr>
    <td width="378"><p>The example1() function opens (or creates) a repository by building a series of client-side objects, culminating in a "connection" object. The connection object will be passed to other methods in TutorialExamples.java. </p>
      <p>We will also make use of the repository's "value factory." </p></td>
    <td width="421"><img src="createconnectionobject.jpg" width="679" height="356"></td>
  </tr>
</table>

<p>The example first connects to an AllegroGraph Server by providing the endpoint (host IP address and port number) of an already-launched AllegroGraph server. You'll also need a user name and password. This creates a client-side server object, which can access the AllegroGraph server's list of available catalogs through the <strong>listCatalogs()</strong> method:</p>
<pre class="input">public class TutorialExamples {

    private static final String SERVER_URL = "http://localhost:8080";
    private static final String CATALOG_ID = "scratch";
    private static final String REPOSITORY_ID = "javatutorial";
    private static final String USERNAME = "test";
    private static final String PASSWORD = "xyzzy";
    private static final File DATA_DIR = new File(".");

    private static final String FOAF_NS = "http://xmlns.com/foaf/0.1/";

    /**
     * Creating a Repository
     */
    public static AGRepositoryConnection example1(boolean close) throws Exception {
        // Tests getting the repository up. 
        println("\nStarting example1().");
        AGServer server = new AGServer(SERVER_URL, USERNAME, PASSWORD);
        println("Available catalogs: " + server.listCatalogs());</pre>
<p>This is the output so far:</p>
<pre class="output">Starting example1().<br>Available catalogs: [/, java-catalog, python-catalog]</pre>
<p>These examples use either the default root catalog (denoted as "/") or catalogs dedicated to specific tutorials. </p>
<p>In the next line of example1(), we use the server's <strong>getRootCatalog()</strong> method to create a client-side catalog object connected to AllegroGraph's default rootCatalog, as defined in the AllegroGraph configuration file. The catalog object has methods such as <strong>getCatalogName()</strong> and <strong>getAllRepositories()</strong> that we can use to investigate the catalogs on the AllegroGraph server. When we look inside the root catalog, we can see which repositories are available:</p>
<pre class="input">        AGCatalog catalog = server.getRootCatalog();<br>        println("Available repositories in catalog " + <br>                (catalog.getCatalogName()) + ": " + <br>                catalog.listRepositories());</pre>
<p>The corresponding output lists the available repositories.  (When you run the examples, you may see a different list of repositories.)</p>
<pre class="output">Available repositories in catalog /: [pythontutorial, javatutorial]</pre>
<p>In the examples, we are careful to close open repositories and to delete previous state before continuing. We are just erasing the blackboard before starting a new lesson. You probably would not do this in your actual application:</p>
<pre class="input">         closeAll();
         catalog.deleteRepository(REPOSITORY_ID); </pre>
<p>The next step is to create a client-side repository object representing the repository we wish to open, by calling the
  <strong>createRepository()</strong> method of the catalog object. We have to provide the name of the desired repository (REPOSITORY_ID in this case, which is bound to the string "javatutorial"). </p>
<pre class="input">        AGRepository myRepository = catalog.createRepository(REPOSITORY_ID);<br>        println("Got a repository.");<br>        myRepository.initialize();<br>        println("Initialized repository.");<br>        println("Repository is writable? " + myRepository.isWritable());</pre>
<p>A new or renewed repository must be initialized, using the <strong>initialize()</strong> method of the repository object. If you try to initialize a repository twice you get a warning message in the Java window but no exception. Finally we check to see that the repository is writable.</p>
<pre class="output">Got a repository.<br>Initialized repository.<br>Repository is writable? true</pre>
<p>The goal of all this object-building has been to create a client-side <strong>repositoryConnection</strong> object, which we casually refer to as the "connection" or "connection object." The repository object's <strong>getConnection()</strong> method returns this connection object. The function <strong>closeBeforeExit()</strong> maintains a list of connection objects and automatically cleans them up when the client exits. </p>
<pre class="input">        AGRepositoryConnection conn = myRepository.getConnection();<br>        closeBeforeExit(conn);<br>        println("Got a connection.");<br>        println("Repository " + (myRepository.getRepositoryID()) +<br>                " is up! It contains " + (conn.size()) +<br>                " statements."              <br>                );</pre>
 <p>The <strong>size()</strong> method of the connection object returns how many triples are present. In the example1() function, this number should always be zero because we deleted and recreated the repository. This is the output in the Java window: </p>
 <pre class="output">Got a connection.<br>Repository javatutorial is up! It contains 0 statements.</pre>
 <p>Whenever you create a new repository, you should stop to consider which kinds of triple indices you will need.&nbsp; This is an important efficiency decision.&nbsp; AllegroGraph uses a set of sorted indices to quickly identify a contiguous block of triples that are likely to match a specific query pattern. </p>
 <p>These indices are identified by names that describe their organization. The default set of indices are called <strong>spogi, posgi, ospgi, gspoi, gposi, gospi</strong>, and<strong> i</strong> , where: </p>
 <ul>
     <li>S stands for the subject URI. </li>
     <li>P stands for the predicate URI. </li>
     <li>O stands for the object URI or literal. </li>
     <li>G stands for the graph URI. </li>
     <li>I stands for the triple identifier (its unique id number within the triple store). </li>
 </ul>
 <p> The order of the letters denotes how the index has been organized. For instance, the <strong>spogi</strong> index contains all of the triples in the store, sorted first by subject, then by predicate, then by object, and finally by graph. The triple id number is present as a fifth column in the index. If you know the URI of a desired resource (the <em>subject</em> value of the query pattern), then the <strong>spogi</strong> index lets you retrieve all triples with that subject as a single block.&nbsp; </p>
 <p>The idea is to provide your respository with the indices that your queries will need, and to avoid maintaining indices that you will never need.&nbsp; </p>
 <p>We can use the connection object's <strong>listValidIndices()</strong> method to examine the list of all possible AllegroGraph triple indices: </p>
 <pre class="input">        List&lt;String&gt; indices = conn.listValidIndices();<br>        println("All valid triple indices: " + indices);</pre>
 <p>This is the list of all possible valid indices:</p>
 <pre class="output">All valid triple indices: [spogi, spgoi, sopgi, sogpi, sgpoi, sgopi, psogi, 
psgoi, posgi, pogsi, pgsoi, pgosi, ospgi, osgpi, opsgi, opgsi, ogspi, ogpsi, 
gspoi, gsopi, gpsoi, gposi, gospi, gopsi, i]</pre>
 <p>AllegroGraph can generate any of these indices if you need them, but it creates only seven indices by default.&nbsp; We can see the current indices by using the connection object's <strong>listIndices()</strong> method:</p>
 <pre class="input">        indices = conn.listIndices();<br>        println("Current triple indices: " + indices);</pre>
 <p>There are currently seven indices:</p>
 <pre class="output">Current triple indices: [i, gospi, gposi, gspoi, ospgi, posgi, spogi]</pre>
 <p>The indices that begin with "g" are sorted primarily by subgraph (or "context").&nbsp; If you application does not use subgraphs, you should consider removing these indices from the repository.&nbsp; You don't want to build and maintain triple indices that your application will never use.&nbsp; This wastes CPU time and disk space.&nbsp; The connection object has a convenient <strong>dropIndex()</strong> method:</p>
 <pre class="input">        println("Removing graph indices...");<br>        conn.dropIndex("gospi");<br>        conn.dropIndex("gposi");<br>        conn.dropIndex("gspoi");<br>        indices = conn.listIndices();<br>        println("Current triple indices: " + indices);</pre>
 <p>Having dropped three of the triple indices, there are now four remaining:</p>
 <pre class="output">Removing graph indices...<br>Current triple indices: [i, ospgi, posgi, spogi]</pre>
 <p>The <strong>i</strong> index is for deleting triples by using the triple id number.&nbsp; The <strong>ospgi</strong> index is sorted primarily by object value, which makes it possible to grab a range of object values as a single block of triples from the index.&nbsp; Similarly, the <strong>posgi</strong> index lets us reach for a block of triples that all share the same predicate.&nbsp; We mentioned previously that the <strong>spogi</strong> index lets us retrieve blocks of triples that all have the same subject URI.&nbsp; </p>
 <p>As it happens, we may have been overly hasty in eliminating all of the graph indices.&nbsp; AllegroGraph can find the right matches as long as there is <em>any</em> one index present, but using the "right" index is much faster.&nbsp; Let's put one of the graph indices back, just in case we need it. We'll use the connection object's<strong> addIndex()</strong> method: </p>
 <pre class="input">        println("Adding one graph index back in...");<br>        conn.addIndex("gspoi");<br>        indices = conn.listIndices();<br>        println("Current triple indices: " + indices);</pre>
 <pre class="output">Adding one graph index back in...<br>Current triple indices: [i, gspoi, ospgi, posgi, spogi]</pre>
 <p>In its default mode, example1() closes the connection. It can optionally return the connection when called by another method, as will occur in several examples below. If you are done with the connection, closing it and shutting it down will free resources.</p>
 <pre class="input">         if (close) {
             conn.close();
             myRepository.shutDown();
             return null;
        }
        return conn;<br>    }</pre>

<h2 id="Asserting and Retracting Triples">Asserting and Retracting Triples (example2()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>




<p>

In example2(), we show how
to create resources describing two
people, Bob and Alice, by asserting individual triples into the repository. The example also retracts and replaces a triple.  Assertions and retractions to the triple store
are executed by 'add' and 'remove' methods belonging to the connection object, which we obtain by calling the example1() function (described above).
</p>
<p>Before asserting a triple, we have to generate the URI values for the subject, predicate and object fields. The Java Sesame API to AllegroGraph Server predefines a number of classes and predicates for the RDF, RDFS, XSD, and OWL ontologies.  RDF.TYPE is one of the predefined predicates we will use. </p>
<p>
The 'add' and 'remove' methods take an optional 'contexts' argument that
specifies one or more subgraphs that are the target of triple assertions
and retractions.  When the context is omitted, triples are asserted/retracted
to/from the background graph.  In the example below, facts about Alice and Bob
reside in the background graph.
</p>
<p>The example2() function begins by calling example1() to create the appropriate connection object, which is bound to the variable <strong>conn</strong>. We will also need the repository's "value factory" object, because it has many useful methods. If we have the connection object, we can retrieve its repository object, and then the value factory. We will need both objects in order to proceed. </p>
<pre class="input">    public static AGRepositoryConnection example2(boolean close) throws RepositoryException {<br>        // Asserts some statements and counts them.<br>        AGRepositoryConnection conn = example1(false);<br>        AGValueFactory vf = conn.getRepository().getValueFactory();<br>        println("Starting example example2().");</pre>
 <p>The next step is to begin assembling the URIs we will need for the new triples. The valueFactory's <strong>createURI()</strong> method generates a URI from a string. These are the subject URIs identifying the resources "Bob" and "Alice":</p>
 <pre class="input">        URI alice = vf.createURI("http://example.org/people/alice");<br>        URI bob = vf.createURI("http://example.org/people/bob");</pre>
 <p>Both Bob and Alice will have a "name" attribute. </p>
 <pre class="input">        URI name = vf.createURI("http://example.org/ontology/name");</pre>
 <p>Bob and Alice will both be rdf:type "Person". Note that this is the name of a class, and is therefore capitalized. </p>
 <pre class="input">        URI person = vf.createURI("http://example.org/ontology/Person");</pre>
 <p>The name attributes will contain literal values. We have to generate the Literal objects from strings: </p>
 <pre class="input">        Literal bobsName = vf.createLiteral("Bob");<br>        Literal alicesName = vf.createLiteral("Alice");</pre>
 <p>The next line prints out the number of triples currently in the repository. </p>
 <pre class="input">        println("Triple count before inserts: " + <br>                (conn.size()));</pre>
<pre class="output">Triple count before inserts:  0
</pre>
<p>Now we assert four triples, two for Bob and two more for Alice, using the connection object's <strong>add()</strong> method. Note the use of RDF.TYPE, which is an attribute of the RDF object in 


 <a href="http://docs.rdf4j.org/javadoc/latest/org/eclipse/rdf4j/model/vocabulary/package-summary.html">org.eclipse.rdf4j.model.vocabulary</a>. This attribute is set the the URI of the rdf:type predicate, which is used to indicate the class of a resource. </p>
<pre class="input">        // Alice's name is "Alice"<br>        conn.add(alice, name, alicesName);<br>        // Alice is a person<br>        conn.add(alice, RDF.TYPE, person);<br>        //Bob's name is "Bob"<br>        conn.add(bob, name, bobsName);<br>        //Bob is a person, too. <br>        conn.add(bob, RDF.TYPE, person);</pre>
<p>After the assertions, we count triples again (there should be four) and print out the triples for inspection. The "null" arguments to the getStatements() method say that we don't want to restrict what values may be present in the subject, predicate, object or context positions. Just print out all the triples. </p>
<pre class="input">        println("Triple count after inserts: " + <br>                (conn.size()));<br>        RepositoryResult&lt;Statement&gt; result = conn.getStatements(null, null, null, false);<br>        while (result.hasNext()) {<br>            Statement st = result.next();<br>            println(st);<br>        }</pre>
<p>This is the output at this point. We see four triples, two about Alice and two about Bob:</p>
<pre class="output">Triple count after inserts: 4
(http://example.org/people/alice, http://example.org/ontology/name, "Alice") [null]
(http://example.org/people/alice, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [null]
(http://example.org/people/bob, http://example.org/ontology/name, "Bob") [null]
(http://example.org/people/bob, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [null]
</pre>
<p>We see two resources of type "person," each with a literal name. The<strong> [null] </strong>value at the end of each triple indicates that the triple is resident in the default background graph, rather than being assigned to a specific named subgraph. </p>
<p>The next step is to demonstrate how to remove a triple. Use the <strong>remove()</strong> method of the connection object, and supply a triple pattern that matches the target triple. In this case we want to remove Bob's name triple from the repository. Then we'll count the triples again to verify that there are only three remaining. Finally, we re-assert Bob's name so we can use it in subsequent examples, and we'll return the connection object.</p>
<pre class="input">        conn.remove(bob, name, bobsName);<br>        println("Removed one triple.");<br>        println("Triple count after deletion: " + <br>                (conn.size()));</pre>
 
 <pre class="output">Removed one triple.<br>Triple count after deletion: 3</pre>
 <p>Example2() ends with a condition that either closes the connection or passes it on to the next method for reuse. </p>
 <h2 id="A SPARQL Query">A SPARQL Query (example3()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>SPARQL stands for  the "<a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL Protocol and RDF Query Language</a>," a recommendation of the <a href="http://www.w3.org/">World Wide Web Consortium (W3C)</a>. SPARQL is a query language for retrieving RDF triples. </p>
 <p>Our next example illustrates how to evaluate a SPARQL query. This is the simplest query, the one that returns all triples. Note that example3() continues with the four triples created in example2(). </p>
 <pre class="input">    public static void example3() throws Exception {<br>        AGRepositoryConnection conn = example2(false);<br>        println("\nStarting example3().");<br>       try {<br>            String queryString = "SELECT ?s ?p ?o  WHERE {?s ?p ?o .}";</pre>
 <p>The SELECT clause returns the variables ?s, ?p and ?o. The variables are bound to the subject, predicate and object values of each triple that satisfies the WHERE clause. In this case the WHERE clause is unconstrained. The dot (.) in the fourth position signifies the end of the pattern. </p>
<p>The connection object's <strong>prepareTupleQuery()</strong> method
  creates a query object that can be evaluated one or more times. (A "tuple" is an ordered sequence of data elements.)   The results are returned in a TupleQueryResult iterator that gives access to a sequence of bindingSets.</p>
<pre class="input">            AGTupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>            TupleQueryResult result = tupleQuery.evaluate();</pre>
<p>Below we illustrate one method for extracting the values
  from a binding set, indexed by the name of the corresponding column variable
in the SELECT clause.</p>
<pre class="input">            try {<br>                while (result.hasNext()) {<br>                    BindingSet bindingSet = result.next();<br>                    Value s = bindingSet.getValue("s");<br>                    Value p = bindingSet.getValue("p");<br>                    Value o = bindingSet.getValue("o");<br>                    System.out.format("%s %s %s\n", s, p, o);<br>                }</pre>
<pre class="output">
http://example.org/people/alice http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://example.org/ontology/Person
http://example.org/people/alice http://example.org/ontology/name "Alice"
http://example.org/people/bob http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://example.org/ontology/Person
http://example.org/people/bob http://example.org/ontology/name "Bob"
</pre>
<p>If one wants only the number of results, using the count() method is more efficient than using evaluate() and counting the returned results client-side.  The repositoryConnection class is designed to be created for the duration of a sequence of updates and queries, and then closed. In practice, many AllegroGraph applications keep a connection open indefinitely. However, best practice dictates that the connection should be closed, as illustrated below. The same hygiene applies to the iterators that generate binding sets.</p>
<pre class="input">
            } finally {
                result.close();
            }
            // Just the count now.  The count is done server-side,
            // and only the count is returned.
            long count = tupleQuery.count();
            println("count: " + count);
        } finally {
            conn.close();
        }
</pre>
<h2 id="Statement Matching">Statement Matching (example4()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>

<p>
The getStatements() method of the connection object provides a simple way to perform unsophisticated queries. This method lets you enter a mix of required values and wildcards, and retrieve all matching triples. (If you need to perform sophisticated tests and comparisons you should use the SPARQL query instead.)</p>
<p>
This is the <strong>example4()</strong> function of TutorialExamples.java. It begins by calling example2() to create a connection object and populate the javarepository with four triples describing Bob and Alice. </p>
<pre class="input">    public static void example4() throws RepositoryException {<br>        RepositoryConnection conn = example2(false);
		closeBeforeExit(conn);</pre>
<p>We're going to search for triples that mention Alice, so we have to create an "Alice" URI to use in the search pattern. This requires us to build the bridge from the connection back to the valueFactory:</p>
<pre class="input">        Repository myRepository = conn.getRepository();<br>        URI alice = myRepository.getValueFactory().createURI("http://example.org/people/alice");</pre>
<p> Now we search for triples with Alice's URI in the subject position.  The "null" values are wildcards for the predicate and object positions of the triple. </p>
<pre class="input">        RepositoryResult&lt;Statement&gt; statements = conn.getStatements(alice, null, null, false);</pre>
<p>The getStatements() method returns a repositoryResult object (bound to the variable "statements" in this case). This object can be iterated over, exposing one result statement at a time. It is sometimes desirable to screen the results for duplicates, using the enableDuplicateFilter() method. Note, however, that duplicate filtering can be expensive. Our example does not contain any duplicates, but it is possible for them to occur. </p>
<pre class="input">        try {<br>            statements.enableDuplicateFilter();<br>            while (statements.hasNext()) {<br>                println(statements.next());<br>            }</pre>
<p>This prints out the two matching triples for "Alice." </p>
<pre class="output">(http://example.org/people/alice, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [null]<br>(http://example.org/people/alice, http://example.org/ontology/name, "Alice") [null]</pre>
<p>At this point it is good form to close the repositoryResponse object because it occupies memory and is rarely reused in most programs. We can also close the connection and shut down the repository. </p>
<pre class="input">        } finally {<br>            statements.close();<br>        }
        conn.close();<br>        myRepository.shutDown();<br>    }</pre>
<h2 id="Literal Values">Literal Values (example5())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>The next example, <strong>example5()</strong>, illustrates some variations on what we have seen so far. The example creates and asserts <a href="http://www.w3.org/TR/rdf-concepts/#section-Graph-Literal">typed and plain literal values</a>, including language-specific plain literals, and then conducts searches for them in three ways:</p>
<ul>
  <li>getStatements() search, which is an efficient way to match a single triple pattern. </li>
  <li>SPARQL direct match, for efficient multi-pattern search. </li>
  <li>SPARQL filter match, for sophisticated filtering such as performing range matches. </li>
</ul>
<p>The getStatements() and SPARQL direct searches return exactly the datatype you ask for. The SPARQL filter queries can sometimes return multiple datatypes. This behavior will be one focus of this section. </p>
<p>If you are not explicit about the datatype of a value, either when asserting the triple or when writing a search pattern, AllegroGraph will deduce an appropriate datatype and use it. This is another focus of this section. This helpful behavior can sometimes surprise you with unanticipated results. </p>
<h3>Setup</h3>
<p>Example5() begins by obtaining a connection object from example1(), and then clears the repository of all existing triples. </p>
<pre class="input">    public static void example5() throws Exception {<br>        RepositoryConnection conn = example2(false);<br>        Repository myRepository = conn.getRepository();<br>        ValueFactory f = myRepository.getValueFactory();<br>        println("\nStarting example5().");<br>        conn.clear();</pre>
<p>
For sake of coding efficiency, it is good practice to create variables
for namespace strings. We'll use this namespace again and again in the
following lines. We have made the URIs in this example very short to
keep the result displays compact.
</p>
<pre class="input">
        String exns = "http://people/";
</pre>
<p>
The example creates new resources describing seven people, named
alphabetically from Alice to Greg. These are URIs to use in the
subject field of the triples. The example shows how to enter a full
URI string (Alice through Dave), or alternately how to combine a
namespace with a local resource name (Eric through Greg).
</p>
<pre class="input">
        URI alice = f.createURI("http://people/alice");
        URI bob = f.createURI("http://people/bob");
        URI carol = f.createURI("http://people/carol");
        URI dave = f.createURI("http://people/dave");
<br>
        URI eric = f.createURI(exns, "eric");
        URI fred = f.createURI(exns, "fred");
        URI greg = f.createURI(exns "greg");
</pre>
<h3>Numeric Literal Values </h3>
<p>This section explores the behavior of numeric literals.</p>
<h3>Asserting Numeric Data</h3>
<p>The first section assigns ages to the  participants, using a variety of numeric types. First we need a URI for the "age" predicate. </p>
<pre class="input">        URI age = f.createURI(exns, "age");</pre>
<p>The next step is to create a variety of values representing ages. Coincidentally, these people are all 42 years old, but we're going to record that information in multiple ways:</p>
<pre class="input">        Literal fortyTwo = f.createLiteral(42);          // creates int<br>        Literal fortyTwoDecimal = f.createLiteral(42.0); // creates float<br>        Literal fortyTwoInt = f.createLiteral("42", XMLSchema.INT);<br>        Literal fortyTwoLong = f.createLiteral("42", XMLSchema.LONG);<br>        Literal fortyTwoFloat = f.createLiteral("42", XMLSchema.FLOAT);<br>        Literal fortyTwoString = f.createLiteral("42", XMLSchema.STRING); <br>        Literal fortyTwoPlain = f.createLiteral("42");   // creates plain literal</pre>
<p>In four of these statements, we explicitly identified the datatype of the value in order to create an INT, a LONG, a DOUBLE and a STRING. This is the best practice. </p>
<p>In three other statements, we just handed AllegroGraph numeric-looking values to see what it would do with them. As we will see in a moment, 42 creates an INT, 42.0 becomes into a DOUBLE, and "42" becomes a "plain" (untyped) literal value. (Note that plain literals are not <em>quite </em>the same thing as typed literal strings. A search for a plain literal will not always match a typed string, and <em>vice versa</em>.)</p>
<p>Now we need to assemble the URIs and values into statements (which are client-side triples):</p>
<pre class="input">        Statement stmt1 = f.createStatement(alice, age, fortyTwo);<br>        Statement stmt2 = f.createStatement(bob, age, fortyTwoDecimal);<br>        Statement stmt3 = f.createStatement(carol, age, fortyTwoInt);<br>        Statement stmt4 = f.createStatement(dave, age, fortyTwoLong);<br>        Statement stmt5 = f.createStatement(eric, age, fortyTwoFloat);<br>        Statement stmt6 = f.createStatement(fred, age, fortyTwoString);<br>        Statement stmt7 = f.createStatement(greg, age, fortyTwoPlain);</pre>
<p>And then add the statements to the triple store on the AllegroGraph server. We can use either <strong>add()</strong> or <strong>addStatement()</strong> for this purpose. </p>
<pre class="input">        conn.add(stmt1);<br>        conn.add(stmt2);<br>        conn.add(stmt3);<br>        conn.add(stmt4);<br>        conn.add(stmt5);<br>        conn.add(stmt6);<br>        conn.add(stmt7);</pre>
<p>Now we'll complete the round trip to see what triples we get back from these assertions. This is how we use <strong>getStatements()</strong> in this example to retrieve and display age triples for us:</p>
<pre class="input">        println("\nShowing all age triples using getStatements().  Seven matches.");<br>        RepositoryResult&lt;Statement&gt; statements = conn.getStatements(null, age, null, false);<br>        try {<br>            while (statements.hasNext()) {<br>                println(statements.next());<br>            }<br>        } finally {<br>            statements.close();<br>        }</pre>
<p>This loop prints all age triples to the interaction window. Note that the retrieved triples are of six types: two ints, a long, a float, a double, a long, a string, and a "plain literal." All of them say that their person's age is 42. Note that the triple for Greg has the plain literal value "42", while the triple for Fred uses "42" as a string.</p>
<pre class="output">Showing all age triples using getStatements().  Seven matches.  <br>(http://people/greg, http://people/age, "42") [null]<br>(http://people/fred, http://people/age, "42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;) [null]<br>(http://people/eric, http://people/age, "4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;) [null]<br>(http://people/dave, http://people/age, "42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;) [null]<br>(http://people/carol, http://people/age, "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;) [null]<br>(http://people/bob, http://people/age, "4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;) [null]<br>(http://people/alice, http://people/age, "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;) [null]</pre>
<p>If you ask AllegroGraph for a specific datatype, you will get it. If you leave the decision up to AllegroGraph, you might get something unexpected such as an plain literal value. </p>
<h3>Matching Numeric Data</h3>
<p>This section explores getStatements() and SPARQL matches against numeric triples. </p>
<p><strong>Match 42.</strong> In the first example, we asked AllegroGraph to find an untyped number, <strong>42.</strong> </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, 42, false)</td>
    <td>Illegal argument.</td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p 42 .}</td>
    <td>No matches. </td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = 42)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;<br>
"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
</table>
<p>The getStatements() query cannot accept a text input parameter, so that experiment won't run. The SPARQL direct match didn't know how to interpret the untyped value and found zero matches. The SPARQL filter match, however, opened the doors to matches of multiple numeric types, and returned ints, floats, longs and doubles. </p>
<p><strong>"Match 42.0"</strong> without explicitly declaring the number's type.</p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, 42.0, false)</td>
    <td><p>Illegal argument. </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p 42.0 .}</td>
    <td>No direct matches. </td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = 42.0)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;<br>
"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
</table>
<p>The getStatements() method cannot accept this input. The filter match returned all numeric types that were equal to 42.0.</p>
<p><strong>"Match '42'^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;."</strong> Note that we have to use a variable (fortyTwoInt) bound to a Literal value in order to offer this int to getStatements(). We can't just type the value into the getStatements() method directly. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, fortyTwoInt, false)</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;</td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;<br>
"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
</table>
<p>Both the getStatements() query and the SPARQL direct query returned exactly what we asked for: ints. The filter match returned all numeric types that matches in value. </p>
<p><strong>"Match '42'^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;."</strong> Again we need a bound variable to offer a Literal value to getStatements(). </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, fortyTwoLong, false)</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;</td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;<br>
"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
</table>
<p>Both the getStatements() query and the SPARQL direct query returned longs. The filter match returned all numeric types. </p>
<p><strong>"Match '42'^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;."</strong> </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, fortyTwoDouble, false)</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "42"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "42"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#float&gt;<br>
"42"^^&lt;http://www.w3.org/2001/XMLSchema#long&gt;<br>
"4.2E1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</td>
  </tr>
</table>
<p>Both the getStatements() query and the SPARQL direct query returned doubles. The filter match returned all numeric types. </p>
<h2>Matching Numeric Strings and Plain Literals</h2>
<p>At this point we are transitioning from tests of numeric matches to tests of string matches, but there is a gray zone to be explored first. What do we find if we search for strings that contain numbers? In particular, what about "plain literal" values that are almost, but not quite, strings?</p>
<p><strong>"Match '42'^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;."</strong> This example asks for a typed string to see if we get any numeric matches back. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, fortyTwoString, false)</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
        It did not match the plain literal. <br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;}</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"42" This is the plain literal value. </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;)}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"42" This is the plain literal value. </td>
  </tr>
</table>
<p>The getStatements() query matched a literal string only. The SPARQL queries returned matches that were both typed strings and plain literals. There were no numeric matches. </p>
<p><strong>"Match plain literal '42'."</strong> This example asks for a plain literal to see if we get any numeric matches back. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, fortyTwoPlain, false)</td>
    <td><p>"42" This is the plain literal. It did not match the string. <br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "42"}</td>
    <td><p>"42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"42" This is the plain literal value. </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "42")}</td>
    <td>"42"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"42" This is the plain literal value. </td>
  </tr>
</table>
<p>The getStatements() query matched the plain literal only, and did not match the string. The SPARQL queries returned matches that were both typed strings and plain literals. There were no numeric matches. </p>
<p>The interesting lesson here is that AllegroGraph distinguishes between strings and plain literals when you use getStatements(), but it lumps them together when you use SPARQL. </p>
<h2>Matching Strings</h2>
<p>In this section we'll set up a variety of string triples and experiment with matching them using getStatements() and SPARQL. Note that <a href="#Free Text Search">Free Text Search</a> is a different topic. In this section we're doing simple matches of whole strings.</p>
<h3>Asserting String Values </h3>
<p>We're going to add a "favorite color" attribute to five of the person resources we have used so far. First we need a predicate.</p>
<pre class="input">        URI favoriteColor = f.createURI(exns, "favoriteColor");</pre>
<p>Now we'll create a variety of string values, and a single "plain literal" value. </p>
<pre class="input">        Literal UCred = f.createLiteral("Red");<br>        Literal LCred = f.createLiteral("red");<br>        Literal RedPlain = f.createLiteral("Red");<br>        Literal rouge = f.createLiteral("rouge", XMLSchema.STRING);<br>        Literal Rouge = f.createLiteral("Rouge", XMLSchema.STRING);<br>        Literal RougePlain = f.createLiteral("Rouge");<br>        Literal FrRouge = f.createLiteral("Rouge", "fr");</pre>
<p>Note that in the last line we created a plain literal and assigned it a French language tag. <em>You cannot assign a language tag to strings, only to plain literals.</em> See <a href="http://www.w3.org/TR/rdf-concepts/#section-Graph-Literal">typed and plain literal values</a> for the specification.</p>
<p>Next we'll add these values to new triples in the triple store. </p>
<pre class="input">        conn.add(alice, favoriteColor, UCred);<br>        conn.add(bob, favoriteColor, LCred);<br>        conn.add(carol, favoriteColor, RedPlain);<br>        conn.add(dave, favoriteColor, rouge);<br>        conn.add(eric, favoriteColor, Rouge);<br>        conn.add(fred, favoriteColor, RougePlain);<br>        conn.add(greg, favoriteColor, FrRouge);</pre>
<p>If we run a getStatements() query for all favoriteColor triples, we get these values returned:</p>
<pre class="input">Showing all color triples using getStatements().  Should be seven.<br>(http://people/greg, http://people/favoriteColor, "Rouge"@fr) [null]<br>(http://people/fred, http://people/favoriteColor, "Rouge") [null]<br>(http://people/eric, http://people/favoriteColor, "Rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;) [null]<br>(http://people/dave, http://people/favoriteColor, "rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;) [null]<br>(http://people/carol, http://people/favoriteColor, "Red") [null]<br>(http://people/bob, http://people/favoriteColor, "red"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;) [null]<br>(http://people/alice, http://people/favoriteColor, "Red"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;) [null]</pre>
<p>That's four typed strings, capitalized and lower case, plus three plain literals, one with a language tag. </p>
<h3>Matching String Data</h3>
<p>First let's search for "Red" without specifying a datatype. </p>
<p><strong>"Match 'Red'."</strong> What happens if we search for "Red" without specifying a string datatype? </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, "Red", false)</td>
    <td><p>Illegal value. <br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "Red"}</td>
    <td><p>"Red"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"Red" This is the plain literal value.</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "Red")}</td>
    <td>"Red"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"Red" This is the plain literal value.</td>
  </tr>
</table>
<p>The getStatements() query cannot accept the "Red" argument and cannot run. The SPARQL queries matched both "Red" typed strings and "Red" plain literals, but they did not return the lower case "red" triple. The match was liberal regarding datatype but strict about case. </p>
<p>Let's try "Rouge".</p>
<p><strong>"Match 'Rouge'."</strong> What happens if we search for "Rouge" without specifying a string datatype or language? Will it match the triple with the French tag? </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, "Rouge", false)</td>
    <td><p>Illegal. <br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "Rouge"}</td>
    <td><p>"Rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"Rouge" This is the plain literal value. <br>
        Did not match the "Rouge"@fr triple. </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "Rouge")}</td>
    <td>"Rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>
"Rouge" This is the plain literal value. <br>
      Did not match the"Rouge"@fr triple. </td>
  </tr>
</table>
<p>The getStatements() query could not proceed because of the illegal argument. The SPARQL queries matched both "Rouge" typed strings and "Rouge" plain literals, but they did not return the "Rouge"@fr triple. The match was liberal regarding datatype but strict about language. We didn't ask for French, so we didn't get French. </p>
<p><strong>"Match 'Rouge'@fr."</strong> What happens if we search for "Rouge"@fr? We'll have to bind the value to a variable (FrRouge) to use getStatements(). We can type the value directly into the SPARQL queries. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, age, FrRouge, false)</td>
    <td><p>"Rouge"@fr <br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "Rouge"@fr}</td>
    <td><p>"Rouge"@fr </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "Rouge"@fr)}</td>
    <td>"Rouge"@fr </td>
  </tr>
</table>
<p>
If you ask for a specific language, that's exactly what you are going
to get, in all three types of queries.
</p>
<p>
You may be wondering how to perform a string match where language and
capitalization don't matter. You can do that with a SPARQL filter
query using the <strong>str()</strong> function, which returns the
string portion of a literal, without the datatype or language tag. So
applied to the following, <strong>str()</strong> returns
"Rouge":
</p>
<pre class="output">
  "Rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;
<br>
  "Rouge"
<br>
  "Rouge"@fr
</pre>
<p>
Then the <strong>lowercase()</strong> function eliminates case
issues:
</p>
<pre class="input">PREFIX fn: &lt;http://www.w3.org/2005/xpath-functions#&gt; 
SELECT ?s ?p ?o 
WHERE {?s ?p ?o . filter (fn:lower-case(str(?o)) = "rouge")}</pre>
<p>This query returns a variety of "Rouge" triples:</p>
<pre class="output">  http://people/dave http://people/favoriteColor "rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>  http://people/eric http://people/favoriteColor "Rouge"^^&lt;http://www.w3.org/2001/XMLSchema#string&gt;<br>  http://people/fred http://people/favoriteColor "Rouge"<br>  http://people/greg http://people/favoriteColor "Rouge"@fr</pre>
<p>This query matched all triples containing the string "rouge" regardless of datatype or language tag. Remember that the SPARQL "filter" queries are powerful, but they are also the slowest queries. SPARQL direct queries and getStatements() queries are faster. </p>
<h2>Matching Booleans</h2>
<p>In this section we'll assert and then search for Boolean values.</p>
<h3>Asserting Boolean Values</h3>
<p>We'll be adding a new attribute to the person resources in our example. Are they, or are they not, seniors?</p>
<pre class="input">        URI senior = f.createURI(exns, "senior");</pre>
<p>The correct way to create Boolean values for use in triples is to create literal values of type Boolean:</p>
<pre class="input">        Literal trueValue = f.createLiteral("true", XMLSchema.BOOLEAN);  <br>        Literal falseValue = f.createLiteral("false", XMLSchema.BOOLEAN);</pre>
<p>Note that "true" and "false" must be lower case. </p>
<p>We'll only need two triples:</p>
<pre class="input">        conn.add(alice, senior, trueValue);<br>        conn.add(bob, senior, falseValue);</pre>
<p>When we retrieve the triples (using getStatements()) we see:</p>
<pre class="output">(http://people/bob, http://people/senior, "false"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;) [null]<br>(http://people/alice, http://people/senior, "true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;) [null]</pre>
<p>These are RDF-legal Boolean values that work with the AllegroGraph query engine. </p>
<p><strong>"Match 'true'."</strong> There are three correct ways to perform a Boolean search. One is to use the varible trueValue (defined above) to pass a Boolean literal value to getStatements(). SPARQL queries will recognize <strong>true</strong> and <strong>false</strong>, and of course the fully-typed <strong>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</strong> format is also respected by SPARQL:</p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, senior, trueValue, false)</td>
    <td><p>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p true}</td>
    <td><p>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</td>
    <td>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = true)}</td>
    <td>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;}</td>
    <td>"true"^^&lt;http://www.w3.org/2001/XMLSchema#boolean&gt;</td>
  </tr>
</table>
<p>All of these queries correctly match Boolean values.</p>
<p>In the following example, we use getStatements() to match a DATE object. We have used a DATE literal in the object position of the triple pattern: </p>

<pre class="input">            println("Retrieve triples matching DATE object.");<br>            RepositoryResult&lt;Statement&gt; statements = conn.getStatements(null, null, date, false);<br>            try {<br>                while (statements.hasNext()) {<br>                    println(statements.next());<br>                }<br>            } finally {<br>                statements.close();<br>            }</pre> 
<pre class="output">Retrieve triples matching DATE object.<br>(http://example.org/people/alice, http://example.org/people/birthdate, "1984-12-06"^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;) [null]</pre>
<p>Note the string representation of the DATE object in the following query.  </p>
<pre class="input">            RepositoryResult&lt;Statement&gt; statements = conn.getStatements(null, null,<br>                    f.createLiteral("\"1984-12-06\"^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;"), false);</pre>
<pre class="output">Match triples having specific DATE value.<br>(&lt;http://example.org/people/alice&gt;, &lt;http://example.org/people/birthdate&gt;, "1984-12-06"^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;)
</pre>
<p>Let's try the same experiment with DATETIME:</p>
<pre class="input">           RepositoryResult&lt;Statement&gt; statements = conn.getStatements(null, null, time, false);</pre> 
<pre class="output">Retrieve triples matching DATETIME object.<br>(http://example.org/people/ted, http://example.org/people/birthdate, "1984-12-06T09:00:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;) [null]</pre>



<p>And a DATETIME match without using a literal value object:</p>
<pre class="input">           RepositoryResult&lt;Statement&gt; statements = conn.getStatements(null, null,<br>                    f.createLiteral("\"1984-12-06T09:00:00\"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;"), false);</pre>
<pre class="output">Match triples having a specific DATETIME value.<br>(http://example.org/people/ted, http://example.org/people/birthdate, "1984-12-06T09:00:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;) [null]</pre>
<h3>Dates, Times and Datetimes </h3>
<p>In this final section of example5(), we'll assert and retrieve dates, times and datetimes. </p>
<p>In this context, you might be surprised by the way that AllegroGraph handles time zone data. If you assert (or search for) a timestamp that includes a time-zone offset, AllegroGraph will "normalize" the expression to Greenwich (zulu) time before proceeding. This normalization greatly speeds up searching and happens transparently to you, but you'll notice that the matched values are all zulu times. </p>
<h3>Asserting Date, Time and Datetime Values</h3>
<p>We're going to add birthdates to our personnel records. We'll need a birthdate predicate:</p>
<pre class="input">        URI birthdate = f.createURI(exns, "birthdate");</pre>
<p>We'll also need four types of literal values: a date, a time, a datetime, and a datetime with a time-zone offset.</p>
<pre class="input">        Literal date = f.createLiteral("1984-12-06", XMLSchema.DATE);<br>        Literal datetime = f.createLiteral("1984-12-06T09:00:00", XMLSchema.DATETIME);<br>        Literal time = f.createLiteral("09:00:00", XMLSchema.TIME);<br>        Literal datetimeOffset = f.createLiteral("1984-12-06T09:00:00+01:00", XMLSchema.DATETIME);</pre>
<p>It is interesting to notice that these literal values print out exactly as we defined them. </p>
<pre class="output">Printing out Literals for date, datetime, time, and datetime with Zulu offset.<br>"1984-12-06"^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;<br>"1984-12-06T09:00:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;<br>"09:00:00"^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;<br>"1984-12-06T09:00:00+01:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</pre>
<p>Now we'll add them to the triple store:</p>
<pre class="input">        conn.add(alice, birthdate, date);<br>        conn.add(bob, birthdate, datetime);<br>        conn.add(carol, birthdate, time);<br>        conn.add(dave, birthdate, datetimeOffset);</pre>
<p>And then retrieve them using getStatements():</p>
<pre class="output">getStatements() all birthdates.  Four matches.<br>(http://people/dave, http://people/birthdate, "1984-12-06T08:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;) [null]<br>(http://people/carol, http://people/birthdate, "09:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;) [null]<br>(http://people/bob, http://people/birthdate, "1984-12-06T09:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;) [null]<br>(http://people/alice, http://people/birthdate, "1984-12-06"^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;) [null]</pre>
<p>If you look sharply, you'll notice that the zulu offset has been normalized:</p>
<pre>Was:<span class="output">"1984-12-06T09:00:00+01:00"</span>
Now:<span class="output">"1984-12-06T08:00:00Z"</span></pre>
<p>Note that the one-hour zulu offset has been applied to the timestamp. "9:00" turned into "8:00." </p>
<h3>Matching Date, Time, and Datetime Literals</h3>
<p><strong>"Match date."</strong> What happens if we search for the date literal we defined? We'll use the "date" variable with getStatements(), but just type the expected value into the SPARQL queries. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, birthdate, date, false)</td>
    <td><p>"1984-12-06"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p '1984-12-06'^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;</td>
    <td><p>"1984-12-06"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o =<br>
      '1984-12-06'<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;)}</td>
    <td>"1984-12-06"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#date&gt;</td>
  </tr>
</table>
<p>All three queries match narrowly, meaning the exact date and datatype we asked for is returned. </p>
<p><strong>"Match datetime."</strong> What happens if we search for the datetime literal? We'll use the "datetime" variable with getStatements(), but just type the expected value into the SPARQL queries. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, birthdate, datetime, false)</td>
    <td><p>"1984-12-06T09:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p '1984-12-06T09:00:00Z'<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .}</td>
    <td><p>"1984-12-06T09:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = '1984-12-06T09:00:00Z'^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</td>
    <td>"1984-12-06T09:00:00Z"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</td>
  </tr>
</table>
<p>The matches are specific for the exact date, time and type. </p>
<p><strong>"Match time."</strong> What happens if we search for the time literal? We'll use the "time" variable with getStatements(), but just type the expected value into the SPARQL queries. </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, birthdate, time, false)</td>
    <td><p>"09:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "09:00:00Z"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#time&gt; .}</td>
    <td><p>"09:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "09:00:00Z"^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;)}</td>
    <td>"09:00:00Z"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#time&gt;</td>
  </tr>
</table>
<p>The matches are specific for the exact time and type. </p>
<p><strong>"Match datetime with offset."</strong> What happens if we search for a datetime with zulu offset? </p>
<table width="1038" border="1">
  <tr>
    <td width="140"><strong>Query Type </strong></td>
    <td width="368"><strong>Query</strong></td>
    <td width="508"><strong>Matches which types? </strong></td>
  </tr>
  <tr>
    <td><strong>getStatements()</strong></td>
    <td>conn.getStatements(null, birthdate, datetimeOffset, false)</td>
    <td><p>"1984-12-06T08:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;<br>
    </p></td>
  </tr>
  <tr>
    <td><strong>SPARQL direct match </strong></td>
    <td>SELECT ?s ?p WHERE {?s ?p "1984-12-06T09:00:00+01:00"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt; .}</td>
    <td><p>"1984-12-06T08:00:00Z"<br>
        ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</p></td>
  </tr>
  <tr>
    <td><strong>SPARQL filter match </strong></td>
    <td><p>SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = "1984-12-06T09:00:00+01:00"^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;)}</p></td>
    <td>"1984-12-06T08:00:00Z"<br>
      ^^&lt;http://www.w3.org/2001/XMLSchema#dateTime&gt;</td>
  </tr>
</table>
<p>Note that we searched for "1984-12-06T09:00:00+01:00" but found "1984-12-06T08:00:00Z". It is the same moment in time. </p>
<h2 id="Importing Triples">Importing Triples (example6() and example7()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>
The Java Sesame API client can load triples in either RDF/XML format
or NTriples format.  The example below calls the connection
object's <strong>add()</strong> method to load an NTriples file,
and <strong>addFile()</strong> to load an RDF/XML file. Both methods
work, but the best practice is to use <strong>addFile()</strong>.
</p>
<table width="769" border="2px" cellpadding="4px" style="border-collapse:collapse; border-color:#0000FF;">
  <tr>
    <td width="928"><strong>Note:</strong> If you get a "file not found" error while running this example, it means that Java is looking in the wrong directory for the data files to load. The usual explanation is that you have moved the TutorialExamples.java file to an unexpected directory. You can clear the issue by putting the data files in the same directory as TutorialExamples.java. </td>
  </tr>
</table>
<p>&nbsp;</p>
<p>The RDF/XML file contains a short list of v-cards (virtual business cards), like this one:</p>
<pre>  &lt;rdf:Description rdf:about="http://somewhere/JohnSmith/"&gt;<br>    &lt;vCard:FN&gt;John Smith&lt;/vCard:FN&gt;<br>    &lt;vCard:N rdf:parseType="Resource"&gt;<br>	    &lt;vCard:Family&gt;Smith&lt;/vCard:Family&gt;<br>	    &lt;vCard:Given&gt;John&lt;/vCard:Given&gt;<br>    &lt;/vCard:N&gt;<br>  &lt;/rdf:Description&gt; </pre>
<p>The NTriples file contains a graph of resources describing the Kennedy family, the places where they were each born, their colleges, and their professions. A typical entry from that file looks like this:</p>
<pre>&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#first-name&gt; "Joseph" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#middle-initial&gt; "Patrick" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#last-name&gt; "Kennedy" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#suffix&gt; "none" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#alma-mater&gt; &lt;http://www.franz.com/simple#Harvard&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#birth-year&gt; "1888" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#death-year&gt; "1969" . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#sex&gt; &lt;http://www.franz.com/simple#male&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#spouse&gt; &lt;http://www.franz.com/simple#person2&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#has-child&gt; &lt;http://www.franz.com/simple#person3&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#profession&gt; &lt;http://www.franz.com/simple#banker&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.franz.com/simple#birth-place&gt; &lt;http://www.franz.com/simple#place5&gt; . 
&lt;http://www.franz.com/simple#person1&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://www.franz.com/simple#person&gt; . </pre>

<p>Note that AllegroGraph can segregate triples into contexts (subgraphs) by treating them as quads, but the NTriples and RDF/XML formats can not include context information. They deal with triples only, so there is no place to store a fourth field in those formats. In the case of the <strong>add()</strong> call, we have omitted the context
  argument so the triples are loaded the default background graph (sometimes called the "null context<em>.</em>") </p>
<p>The
  <strong>addFile()</strong> call includes an explicit context setting, so the fourth argument of
  each vcard triple will be the context named "/tutorial/vc_db_1_rdf".  </p>
<p>The <strong>connection size()</strong> method takes an optional context argument.  With no
    argument, it returns the total number of triples in the repository.  Below, it returns the number
    '16' for the named subgraph, and the number '28' for the null context
    (None) argument. </p>
<p>The example6() function of TutorialExamples.java creates a <a href="#Transaction">transaction</a> connection to AllegroGraph, using methods you have seen before, plus the repositoryConnection object's <strong>setAutoCommit()</strong> method: </p>
<pre class="input">
    public static AGRepositoryConnection example6() throws Exception {
        AGServer server = new AGServer(SERVER_URL, USERNAME, PASSWORD);
        AGCatalog catalog = server.getCatalog(CATALOG_ID);
        AGRepository myRepository = catalog.createRepository(REPOSITORY_ID);
        myRepository.initialize();
        AGRepositoryConnection conn = myRepository.getConnection();
        closeBeforeExit(conn);
        conn.clear();
        conn.setAutoCommit(false);  // transaction session
        ValueFactory f = myRepository.getValueFactory();
</pre>
<p>The transaction session is not immediately pertinent to the examples in this section, but will become important in later examples that reuse this connection to demonstrate <a href="#Prolog Rule Queries">Prolog Rules</a> and <a href="#Social Network Analysis">Social Network Analysis</a>. </p>
<p>The variables path1 and path2 are bound to the RDF/XML and NTriples files, respectively. The data files are in the same directory as TutorialExamples.java. If your data files are in another directory, adjust the DATA_DIR constant.</p>
<pre class="input">
        File path1 = new File(DATA_DIR, "java-vcards.rdf"); 
        File path2 = new File(DATA_DIR = "java-kennedy.ntriples");
</pre>
<p>Both examples need a base URI as one of the required arguments to the asserting methods: </p>
<pre class="input">        String baseURI = "http://example.org/example/local";</pre>
<p>The NTriples about the vcards will be added to a specific context, so naturally we need a URI to identify that context. </p>
<pre class="input">        URI context = f.createURI("http://example.org#vcards");</pre>
<p>
In the next step we use <strong>add()</strong> to load the vcard
triples into the #vcards context:
</p>
<pre class="input">
        conn.add(new File(path1), baseURI, RDFFormat.RDFXML, context);
</pre>
<p>
Then we use <strong>add()</strong> to load the Kennedy family tree
into the null context:
</p>
<pre class="input">
        conn.add(new File(path2), baseURI, RDFFormat.NTRIPLES);
</pre>
<p>Now we'll ask AllegroGraph to report on how many triples it sees in the null context and in the #vcards context: </p>
<pre class="input">        println("After loading, repository contains " + conn.size(context) +<br>                " vcard triples in context '" + context + "'\n    and   " +<br>                conn.size((Resource)null) + " kennedy triples in context 'null'.");</pre>
<p>The output of this report was:</p>
<pre class="output">After loading, repository contains 16 vcard triples in context 'http://example.org#vcards'<br>    and   1214 kennedy triples in context 'null'.</pre>
<p><strong>Example7()</strong> borrows the same triples we loaded in example6(), above, and runs two unconstrained retrievals. The first uses getStatement, and prints out the subject URI and context of each triple. </p>
<pre class="input">    public static void example7() throws Exception {<br>        RepositoryConnection conn = example6(false);<br>        println("\nMatch all and print subjects and contexts");<br>        RepositoryResult&lt;Statement&gt; result = conn.getStatements(null, null, null, false);<br>        for (int i = 0; i &lt; 25 &amp;&amp; result.hasNext(); i++) {<br>            Statement stmt = result.next();<br>            println(stmt.getSubject() + "  " + stmt.getContext());<br>        }<br>        result.close();</pre>
<p>This loop prints out a mix of triples from the null context and from the #vcards context. In this case the output contained the 16 v-card triples plus another nine from the Kennedy data. We set a limit of 25 triples on the output because the Kennedy dataset contains over a thousand triples. </p>
<p>The following loop, however, does not produce the same results. This is a SPARQL query that should match all available triples, printing out the subject and context of each triple. We limited this query by using the DISTINCT keyword. Otherwise there would be many duplicate results. </p>
<pre class="input">        println("\nSame thing with SPARQL query (can't retrieve triples in the null context)");<br>        String queryString = "SELECT DISTINCT ?s ?c WHERE {graph ?c {?s ?p ?o .} }";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult qresult = tupleQuery.evaluate();       <br>        while (qresult.hasNext()) {<br>            BindingSet bindingSet = qresult.next();<br>            println(bindingSet.getBinding("s") + "  " + bindingSet.getBinding("c"));<br>        }<br>        qresult.close();<br>        conn.close();</pre>
<p>In this case, the loop prints out only v-card triples from the #vcards context. The SPARQL query is not able to access the null context when a named context is also present. </p>
<h2 id="Exporting Triples">Exporting Triples (example8() and example9()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>The next examples show how to write triples out to a file in either NTriples format or RDF/XML format. The output of either format may be optionally redirected to standard output (the Java command window) for inspection.</p>
<p>Example example8() begins by obtaining a connection object from example6(). This means the repository contains v-card triples in the <strong>#vcards</strong> context, and Kennedy family tree triples in the<strong> null </strong>context (the default graph). </p>
<pre class="input">    public static void example8() throws Exception {<br>        RepositoryConnection conn = example6(false);<br>        Repository myRepository = conn.getRepository();</pre>
<p>In this example, we'll export the triples in the #vcards context. </p>
<pre class="input">        URI context = myRepository.getValueFactory().createURI("http://example.org#vcards");</pre>
<p>To write triples in
NTriples format, call <strong>NTriplesWriter()</strong>. You have to a give it an output stream, which could be either a file path or standard output. The code below gives you the choice of writing to a file or to the interaction window. </p>
<pre class="input">        String outputFile = "/tmp/temp.nt";<br>//        outputFile = null;<br>        if (outputFile == null) {<br>            println("\nWriting n-triples to Standard Out instead of to a file");<br>        } else {<br>            println("\nWriting n-triples to: " + outputFile);<br>        }<br>        OutputStream output = (outputFile != null) ? new FileOutputStream(outputFile) : System.out;<br>        NTriplesWriter ntriplesWriter = new NTriplesWriter(output);<br>        conn.export(ntriplesWriter, context);</pre>
<p>To write triples in RDF/XML format, call <strong>RDFXMLWriter()</strong>. </p>
<pre class="input">        String outputFile2 = "/tmp/temp.rdf";<br>        outputFile2 = null;<br>        if (outputFile2 == null) {<br>            println("\nWriting RDF to Standard Out instead of to a file");<br>        } else {<br>            println("\nWriting RDF to: " + outputFile2);<br>        }<br>        output = (outputFile2 != null) ? new FileOutputStream(outputFile2) : System.out;<br>        RDFXMLWriter rdfxmlfWriter = new RDFXMLWriter(output);<br>        conn.export(rdfxmlfWriter, context);<br>        output.write('\n');<br>        conn.close();</pre>
<p>
The <strong>export()</strong> method writes
  out all triples in one or more contexts.  This provides a convenient means for making
  local backups of sections of your RDF store.  If two or more contexts are specified,
  then triples from all of those contexts will be written to<em> the same file</em>.  Since the
triples are "mixed together" in the file, the context information is not recoverable. If the context argument is omitted, all triples in the store are written out, and again all context information is lost. </p>
<p>Finally, if the objective is to write out a filtered set of triples,
  the <strong>exportStatements()</strong> method can be used.  The example below (from<strong> example9()</strong>) writes
  out all RDF:TYPE declaration triples to standard output. </p>
<pre class="input">        conn.exportStatements(null, RDF.TYPE, null, false, new RDFXMLWriter(System.out));</pre>

<h2 id="Datasets and Contexts">Searching Multiple Graphs   (example10()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>
We have already seen contexts (subgraphs) at work when loading and saving files. In example10() we provide more realistic examples of contexts, and we explore the FROM, FROM DEFAULT, and FROM NAMED clauses of a SPARQL query to see how they interact with multiple subgraphs in the triple store. Finally, we will introduce the <strong>dataset</strong> object. A dataset is a list of contexts that should all be searched simultaneously. It is an object for use with SPARQL queries. </p>
<p>To set up the example, we create six statements, and add two of each to three different contexts: context1, context2, and the null context. The process of setting up the six statements follows the same pattern as we used in the previous examples: </p>
<pre class="input">        String exns = "http://example.org/people/";<br>        <strong>// Create URIs for resources, predicates and classes.</strong><br>        URI alice = f.createURI(exns, "alice");<br>        URI bob = f.createURI(exns, "bob");<br>        URI ted = f.createURI(exns, "ted");        <br>        URI person = f.createURI("http://example.org/ontology/Person");<br>        URI name = f.createURI("http://example.org/ontology/name");<br>        <strong>// Create literal name values.</strong><br>        Literal alicesName = f.createLiteral("Alice");<br>        Literal bobsName = f.createLiteral("Bob");<br>        Literal tedsName = f.createLiteral("Ted");   <br>        <strong>// Create URIs to identify the named contexts.</strong><br>        URI context1 = f.createURI(exns, "context1");      <br>        URI context2 = f.createURI(exns, "context2");  </pre>
<p>The next step is to assert two triples into each of three contexts. </p>
<pre class="input">        <strong>// Assemble new statements and add them to the contexts.</strong> <br>        conn.add(alice, RDF.TYPE, person, context1);<br>        conn.add(alice, name, alicesName, context1);<br>        conn.add(bob, RDF.TYPE, person, context2);<br>        conn.add(bob, name, bobsName, context2);<br>        conn.add(ted, RDF.TYPE, person);<br>        conn.add(ted, name, tedsName);</pre>
<p>Note that the final two statements (about Ted) were added to the null context (the unnamed default graph). </p>
<h3>GetStatements</h3>
<p>The first test uses <strong>getStatements()</strong> to return all triples in all contexts (context1, context2, and null). 


 This is default search behavior, so there is no need to specify the contexts in either the <strong>conn.getStatements()</strong> method. Note that <strong>conn.size()</strong> also reports on all contexts by default. </p>
<pre class="input">        RepositoryResult&lt;Statement&gt; statements = <strong>conn.getStatements(null, null, null, false);</strong><br>        println("\nAll triples in all contexts: " + <strong>(conn.size())</strong>);       <br>        while (statements.hasNext()) {<br>            println(statements.next());            <br>        }</pre>
<p>The output of this loop is shown below. The context URIs are in the fourth position. Triples from the default graph have [null] in the fourth position. </p>
<pre class="output">All triples in all contexts: 6<br>(http://example.org/people/alice, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [http://example.org/people/context1]<br>(http://example.org/people/alice, http://example.org/ontology/name, "Alice") [http://example.org/people/context1]<br>(http://example.org/people/bob, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [http://example.org/people/context2]<br>(http://example.org/people/bob, http://example.org/ontology/name, "Bob") [http://example.org/people/context2]<br>(http://example.org/people/ted, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [null]<br>(http://example.org/people/ted, http://example.org/ontology/name, "Ted") [null]</pre>
<p>The next match explicitly lists 'context1' and 'context2' as the only contexts to participate in the match. It returns four statements. The conn.size() method can also address individual contexts. </p>
<pre class="input">        statements = conn.getStatements(null, null, null, false, <strong>context1, context2</strong>);<br>        println("\nTriples in contexts 1 or 2: " + (conn.size(context1) + conn.size(context2)));        <br>        while (statements.hasNext()) {<br>            println(statements.next());<br>        }</pre>
<p>The output of this loop shows that the triples in the null context have been excluded. </p>
<pre class="output">Triples in contexts 1 or 2: 4<br>(http://example.org/people/bob, http://example.org/ontology/name, "Bob") [http://example.org/people/context2]<br>(http://example.org/people/bob, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [http://example.org/people/context2]<br>(http://example.org/people/alice, http://example.org/ontology/name, "Alice") [http://example.org/people/context1]<br>(http://example.org/people/alice, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [http://example.org/people/context1]</pre>
<p>This time we use getStatements() to search explicitly for triples in the null context or in context 2. Note that you can use conn.size() to report on the null context alone, if you define null to be a resource as shown here. </p>
<pre class="input">        statements = conn.getStatements(null, null, null, false, <strong>null, context2</strong>);<br>        println("\nTriples in contexts null or 2: " + (conn.size((Resource)null) + conn.size(context2)));        <br>        while (statements.hasNext()) {<br>            println(statements.next());<br>        }</pre>
<p>The output of this loop is:</p>
<pre class="output">Triples in contexts null or 2: 4<br>(http://example.org/people/bob, http://example.org/ontology/name, "Bob") [http://example.org/people/context2]<br>(http://example.org/people/bob, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [http://example.org/people/context2]<br>(http://example.org/people/ted, http://example.org/ontology/name, "Ted") [null]<br>(http://example.org/people/ted, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Person) [null]</pre>
<p>The lesson is that getStatements() can freely mix triples from the null context and named contexts. It is all you need as long as the query is a very simple one. </p>
<h3>SPARQL using FROM and FROM NAMED</h3>
<p>In many of our examples we have used a simple SPARQL query to retrieve triples from AllegroGraph's default graph. This has been very convenient but it is also misleading. As soon as we tell SPARQL to search a <em>specific</em> graph, we lose the ability to search AllegroGraph's default graph! Triples from the null graph vanish from the search results. Why is that? </p>
<ul>
  <li style="margin-bottom: 15px ">It is important to understand that AllegroGraph and SPARQL use the phrase "default graph" to identify two very different things. AllegroGraph's default graph, or null context, is simply the set of all triples that have "null" in the fourth field of the "triple." The "default graph" is an unnamed subgraph of the AllegroGraph triple store. </li>
  <li>SPARQL uses "default graph" to describe something that is very different. In SPARQL, the "default graph" is a temporary pool of triples imported from one or more "named" graphs. SPARQL's "default graph" is constructed and discarded in the service of a single query. </li>
</ul>
<p>Standard SPARQL was designed for <em>named graphs only</em>, and has no syntax to indentify a truly unnamed graph. AllegroGraph's SPARQL, however, has been extended to allow the unnamed graph to participate in multi-graph queries. </p>
<p>We can use AllegroGraph's SPARQL to search specific subgraphs in three ways. We can create a temporary "default graph" using the FROM operator; we can put AllegroGraph's unnamed graph into SPARQL's default graph using FROM DEFAULT; or we can target specific named graphs using the FROM NAMED operator. </p>
<p>We can use SPARQL to search specific subgraphs in two ways. We can create a temporary "default graph" using the FROM operator, or we can target specific named graphs using the FROM NAMED operator. </p>
<ul>
  <li style="margin-bottom: 15px "><strong>FROM</strong> takes one (or more) subgraphs identified by their URIs and temporarily turns them into a single default graph.&nbsp; We match triples in this graph using simple (non-GRAPH) patterns. </li>
  <li style="margin-bottom: 15px "><strong>FROM DEFAULT</strong> takes AllegroGraph's null graph and temporarily makes it part of SPARQL's default graph. Again, we use simple patterns to match this graph.</li>
  <li><strong>FROM NAMED</strong> takes one (or more) named graphs, and declares them to be named graphs in the query.&nbsp; Named graphs must be addressed using explicit GRAPH patterns. </li>
</ul>
<p> We can also combine these operators in a single query, to search the SPARQL default graph and one or more named graphs at the same time. </p>
<p>The first example is a SPARQL query that used FROM DEFAULT to place AllegroGraph's unnamed graph into SPARQL's default graph.&nbsp; </p>
<pre class="input">SELECT ?s ?p ?o FROM DEFAULT <br>WHERE {?s ?p ?o . }</pre>
<p>This query finds triples from the unnamed graph only (which are triples about Ted).&nbsp; Note the simple query pattern. 
<pre class="output">[s=http://example.org/people/ted;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/ted;p=http://example.org/ontology/name;o="Ted"]</pre>
<p>Here's an example of a query that uses FROM. It instructs SPARQL to regard context1 as the default graph for the purposes of this query. </p>
<pre class="input">SELECT ?s ?p ?o 
FROM &lt;http://example.org/people/context1&gt; 
WHERE {?s ?p ?o . }</pre>
<p>SPARQL uses the pattern {?s ?p ?o . } to match triples in context1, which is the temporary default graph:</p>
<pre class="output">SELECT ?s ?p ?o FROM &lt;http://example.org/people/context1&gt; WHERE {?s ?p ?o . }<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice"]</pre>
<p>Notice that these query results do not have the fourth value we have come to expect.&nbsp; That was stripped off when context1 became the (temporary) default context.&nbsp; </p>
<p>The next example changes FROM to FROM NAMED in the same query:</p>
<pre class="input">SELECT ?s ?p ?o 
FROM NAMED &lt;http://example.org/people/context1&gt; 
WHERE {?s ?p ?o . }</pre>
<p>This time there are no matches! The pattern {?s ?p ?o . } only matches the (SPARQL) default graph. We declared context1 to be a "named" graph, so it is no longer the default graph. To match triples in named graphs, SPARQL requires a GRAPH pattern: </p>
<pre class="input">SELECT ?s ?p ?o ?g 
FROM NAMED &lt;http://example.org/people/context1&gt; 
WHERE {GRAPH ?g {?s ?p ?o . }}";</pre>
<p>When we combine GRAPH with FROM NAMED, we get the expected matches: </p>
<pre class="output">SELECT ?s ?p ?o ?g FROM NAMED &lt;http://example.org/people/context1&gt; WHERE {GRAPH ?g {?s ?p ?o . }}<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person;g=http://example.org/people/context1]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice";g=http://example.org/people/context1]</pre>
<p>What about a combination query? The graph commands can be mixed in a single query.</p>
<pre class="input">SELECT ?s ?p ?o ?g <br>FROM DEFAULT<br>FROM &lt;http://example.org/people/context1&gt;<br>FROM NAMED &lt;http://example.org/people/context2&gt; <br>WHERE {{GRAPH ?g {?s ?p ?o . }} UNION {?s ?p ?o .}}</pre>
<p>This query puts AllegroGraph's unnamed graph and the context1 graph into SPARQL's default graph, where the triples can be found by using a simple {?s ?p ?o . } query.&nbsp; Then it identifies context2 as a named graph, which can be searched using a GRAPH pattern.&nbsp; In the final line, we used a UNION operator to combine the matches of the simple and GRAPH patterns. </p>
<p>This query should find all six triples, and here they are: </p>
<pre class="output">[s=http://example.org/people/bob;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person;g=http://example.org/people/context2]<br>[s=http://example.org/people/bob;p=http://example.org/ontology/name;o="Bob";g=http://example.org/people/context2]<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice"]<br>[s=http://example.org/people/ted;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/ted;p=http://example.org/ontology/name;o="Ted"]</pre>
<h2 id="Namespaces"></h2>
<h3>SPARQL with Dataset Object</h3>
<p>Next, we switch to SPARQL queries where the subgraphs are constrained by RDF4J dataset objects. First we'll run the wide-open SPARQL query to see what it finds. In the next two SPARQL examples, we will control the scope of the search by using datasets. A dataset contains  lists of contexts to search, and is applied to the tupleQuery object to control the scope of the search. </p>
<p>Here's the wide-open search, which contains no information about which graph we want to search:</p>
<pre class="input">        String queryString = "SELECT ?s ?p ?o WHERE {?s ?p ?o . }";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();    <br>        println("\n" + queryString);<br>        while (result.hasNext()) {<br>            println(result.next());<br>        }</pre>
<p>In this case the query returns triples from AllegroGraph's default graph <em>and </em>from both named graphs. This accommodates the person who just wants to "search everything." </p>
<pre class="output">SELECT ?s ?p ?o WHERE {?s ?p ?o . } No dataset restrictions.<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice"]<br>[s=http://example.org/people/bob;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/bob;p=http://example.org/ontology/name;o="Bob"]<br>[s=http://example.org/people/ted;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/ted;p=http://example.org/ontology/name;o="Ted"] </pre>
<p>A dataset object is an RDF4J construct that contains two lists of named graphs. There is one list of graphs that will become the SPARQL default graph, just like using FROM in the query. There is a second list of graphs that will be "named" graphs in the query, just like using FROM NAMED. To use the dataset, we put the graph URIs into the dataset object, and then add the dataset to the tupleQuery object. When we evaluate the tupleQuery, the results will be confined to the graphs listed in the dataset. </p>
<p>The next example shows how to use an AllegroGraph <strong>dataset</strong> object in an exceptional way, to restrict the SPARQL query to the triples in AllegroGraph's default graph. Since SPARQL has no way to identify a nameless graph, we use a programmer's trick. To search the default graph only, you must pass an <em>empty dataset</em> <em>object</em> to the query using the <strong>setDataset()</strong> method. </p>
<pre class="input">        queryString = "SELECT ?s ?p ?o WHERE {?s ?p ?o . }";<br>        <strong>ds = new DatasetImpl();</strong><br>        tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        <strong>tupleQuery.setDataset(ds);</strong><br>        result = tupleQuery.evaluate();    <br>        println("\nQuery over the null context.");<br>        while (result.hasNext()) {<br>            println(result.next());<br>        }</pre>

<p>The output of this loop is the two triples that are in the default graph:</p>
<!-- TODO Java was returning six triples, should be two. -->
<pre class="output">Query over the null context.<br>['&lt;http://example.org/people/ted&gt;', '&lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt;', '&lt;http://example.org/people/Person&gt;']
['&lt;http://example.org/people/ted&gt;', '&lt;http://example.org/people/name&gt;', '"Ted"']</pre>
<p>This time we'll add a graph to the dataset using the<strong> addNamedGraph() </strong>method. This time  the wide-open query is restricted to only those statements in context1, which will be treated as a "named graph" in the query:</p>
<pre class="input">        queryString = "SELECT ?s ?p ?o WHERE {?s ?p ?o . }";<br>        <strong>ds = new DatasetImpl();</strong><br>        <strong>ds.addNamedGraph(context1);</strong><br>        tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        <strong>tupleQuery.setDataset(ds);</strong><br>        result = tupleQuery.evaluate();    <br>        println("\n" + queryString + " Datasest for context1.");<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            println(bindingSet.getBinding("s") + " " + <br>            		bindingSet.getBinding("p") + " " +<br>            		bindingSet.getBinding("o"));<br>        }    </pre>
<p>The output of this query is somewhat unexpected. The query returns no results! </p>
<pre class="output">SELECT ?s ?p ?o WHERE {?s ?p ?o . } Datasest for context1.</pre>
<p>Why did this happen? Once we explicitly identify a subgraph as a "named graph" in the query, SPARQL insists that we use a GRAPH pattern. The following example uses a dataset to target context1, and adds a GRAPH element to the query. This small change lets us focus on one subgraph only. </p>
<pre class="input">        queryString = "SELECT ?s ?p ?o ?c WHERE { <strong>GRAPH ?c {?s ?p ?o . } </strong>}";        <br>        <strong>ds = new DatasetImpl();<br>        ds.addNamedGraph(context1);</strong><br>        tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        <strong>tupleQuery.setDataset(ds);</strong><br>        result = tupleQuery.evaluate();    <br>        println("\n" + queryString + " Datasest for context1, using GRAPH.");<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            println(bindingSet.getBinding("s") + " " + <br>            		bindingSet.getBinding("p") + " " +<br>            		bindingSet.getBinding("o") + " " +<br>            		bindingSet.getBinding("c"));<br>        } </pre>
<p>The output of this loop contains two triples, as expected. These are the triples from context1.</p>
<pre class="output">SELECT ?s ?p ?o ?c WHERE { GRAPH ?c {?s ?p ?o . } } Datasest for context1, using GRAPH.<br>s=http://example.org/people/alice p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type o=http://example.org/ontology/Person c=http://example.org/people/context1<br>s=http://example.org/people/alice p=http://example.org/ontology/name o="Alice" c=http://example.org/people/context1</pre> 
<p>One naturally wonders what the SPARQL GRAPH query would find if we got out of its way and ran it without any dataset restrictions. Here it is:</p>
<pre class="input">        queryString = "SELECT ?s ?p ?o ?c WHERE {GRAPH ?c {?s ?p ?o . }}";<br>        tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        result = tupleQuery.evaluate();    <br>        println("\n" + queryString + " No dataset. SPARQL GRAPH query only.");<br>        while (result.hasNext()) {<br>            println(result.next());<br>        }</pre>
<p>The output of this loop contains four triples, two from each of the named subgraphs in the store (context1 and context2). The query was not able to find the triples that were in the AllegroGraph default graph. </p>
<pre class="output">SELECT ?s ?p ?o ?c WHERE {GRAPH ?c {?s ?p ?o . }} No dataset. SPARQL GRAPH query only.<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person;c=http://example.org/people/context1]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice";c=http://example.org/people/context1]<br>[s=http://example.org/people/bob;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person;c=http://example.org/people/context2]<br>[s=http://example.org/people/bob;p=http://example.org/ontology/name;o="Bob";c=http://example.org/people/context2]</pre>

<h3>Namespaces (example11()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h3>
<p>
A <i>namespace</i> is that portion of a URI that precedes the last '#',
'/', or ':' character, inclusive.  The remainder of a URI is called the
<i>localname</i>.  For example, with respect to the URI "http://example.org/people/alice",
the namespace is "http://example.org/people/" and the localname is "alice".
When writing SPARQL queries, it is convenient to define prefixes or nicknames
for the namespaces, so that abbreviated URIs can be specified.  For example,
if we define "ex" to be a nickname for "http://example.org/people/", then the
string "ex:alice" is a recognized abbreviation for "http://example.org/people/alice".
This abbreviation is called a <i>qname</i>.
</p>
<p>
In the SPARQL query in the example below, we see two qnames, "rdf:type" and
"ex:alice".  Ordinarily, we would expect to see "PREFIX" declarations in
SPARQL that define namespaces for the "rdf" and "ex" nicknames.  However,
the RepositoryConnection and Query machinery can do that job for you.  The
mapping of prefixes to namespaces includes the built-in prefixes RDF, RDFS, XSD, and OWL.
Hence, we can write "rdf:type" in a SPARQL query, and the system already knows
its meaning.  In the case of the 'ex' prefix, we need to instruct it.  The
setNamespace() method of the connection object registers a new namespace.  In the example
below, we first register the 'ex' prefix, and then submit the SPARQL query.
It is legal, although not recommended, to redefine the built-in prefixes RDF, etc..
</p>
<p>The example example11() begins by borrowing a connection object from example1(). Then we retrieve the repository object and its associated valueFactory. </p>
<pre class="input">    public static void example11 () throws Exception {<br>        RepositoryConnection conn = example1(false);<br>        Repository myRepository = conn.getRepository();<br>        ValueFactory f = myRepository.getValueFactory();</pre>
<p>We need a namespace string (bound to the variable <strong>exns</strong>) to use when generating the <strong>alice</strong> and <strong>person</strong> URIs. </p>
<pre class="input">        String exns = "http://example.org/people/";<br>        URI alice = f.createURI(exns, "alice");<br>        URI person = f.createURI(exns, "Person");</pre>
<p>Now we can assert Alice's RDF:TYPE triple. </p>
<pre class="input">        conn.add(alice, RDF.TYPE, person);</pre>
<p>Now we register the exns namespace with the connection object, so we can use it in a SPARQL query. The query looks for triples that have "rdf:type" in the predicate position, and "ex:Person" in the object position. </p>
<pre class="input">        conn.setNamespace("ex", exns);<br>        String queryString = <br>        	"SELECT ?s ?p ?o " +<br>        	"WHERE { ?s ?p ?o . FILTER ((?p = rdf:type) &amp;&amp; (?o = ex:Person) ) }";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();  <br>        while (result.hasNext()) {<br>            println(result.next());<br>        }</pre>
<p>The output shows the single triple with its fully-expanded URIs.  This demonstrates that the qnames in the SPARQL query successfully matched the fully-expanded URIs in the triple. </p>
<pre class="output">[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/people/Person]</pre>
<p>It is worthwhile to briefly discuss performance here.  In the current
  AllegroGraph system, queries run more efficiently if constants appear inside
  of the "where" portion of a query, rather than in the "filter" portion.  For
  example, the SPARQL query below will evaluate more efficiently than the one
  in the above example.  However, in this case, you have lost the ability to
  output the constants "http://www.w3.org/1999/02/22-rdf-syntax-ns#type" and
"http://example.org/people/alice".  Occasionally you may find it useful to
  output constants in the output of a 'select' clause; in general though,
  the above code snippet illustrates a query syntax that is discouraged. </p>
<pre class="input">
SELECT ?s  
WHERE { ?s rdf:type ex:person } 
</pre>

<h2 id="Free Text Search">Free Text Search (example12()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p> It is common for users to build RDF applications that combine 
some form of "keyword search" with their queries. For example, a user might want to retrieve all triples for which the string "Alice" appears as a word within the third (object) argument to the triple. AllegroGraph provides a capability for including free text matching within a SPARQL query. It requires, however, that you create and configure indexes appropriate to the searches you want to pursue. </p>
<p> The example example12() begins by borrowing the connection object from example1(). Then it creates a namespace string and registers the namespace with the connection object, as in the previous example. </p>
<pre class="input">	public static void example12 () throws Exception {    <br>        AGRepositoryConnection conn = example1(false);<br>	    ValueFactory f = conn.getValueFactory();<br>	    String exns = "http://example.org/people/";<br>	    conn.setNamespace("ex", exns);</pre>
<p> We have to create an index. AllegroGraph lets you create any number of text indexes, each for a specific purpose. In this case we are indexing the literal values we find in the "fullname" predicate, which we will use in resources that describe people. The <strong>createFreeTextIndex()</strong> method has many configurable parameters. Their default settings are appropriate to this situation. All we have to provide is a name for the index and the URI of the predicate (or predicates) that contain the text to be indexed. </p>
<pre class="input">	    conn.createFreetextIndex("index1", new URI[]{f.createURI(exns,"fullname")});</pre>
<p>The next step is to create two new resources, "Alice1" named "Alice B. Toklas," and "book1" with the title "Alice in Wonderland." Notice that we did not register the book title predicate for text indexing. </p>
<pre class="input">	    URI alice = f.createURI(exns, "alice1");<br>	    URI persontype = f.createURI(exns, "Person");<br>	    URI fullname = f.createURI(exns, "fullname");    <br>	    Literal alicename = f.createLiteral("Alice B. Toklas");<br>	    URI book =  f.createURI(exns, "book1");<br>	    URI booktype = f.createURI(exns, "Book");<br>	    URI booktitle = f.createURI(exns, "title");    <br>	    Literal wonderland = f.createLiteral("Alice in Wonderland");</pre>
<p>Clear the repository, so our new triples are the only ones available. </p>
<pre class="input">
        conn.clear()    </pre>
<p>Add the resource for the new person, Alice B. Toklas: </p>
<pre class="input">	    conn.add(alice, RDF.TYPE, persontype);<br>	    conn.add(alice, fullname, alicename);</pre>
<p>Add the new book, <em>Alice in Wonderland</em>. </p>
<pre class="input">	    conn.add(book, RDF.TYPE, booktype);    <br>	    conn.add(book, booktitle, wonderland); </pre>
<p>Now we set up the SPARQL query that looks for triples containing "Alice" in the object position. </p>
<p>The text match occurs through a "magic" predicate called <strong>fti:match</strong>. This is not an RDF "predicate" but a LISP "predicate," meaning that it behaves as a true/false test. This predicate has two arguments. One is the subject URI of the resources to search. The other is the string pattern to search for, such as "Alice". Only registered text predicates will be searched. Only full-word matches will be found. </p>
<pre class="input">	    String queryString = <br>	        "SELECT ?s ?p ?o " +<br>	        "WHERE { ?s ?p ?o . 
                     ?s fti:match 'Alice' . }";</pre>
<p>There is no need to include a prefix declaration for the 'fti' nickname. That is because 'fti' is included among the built-in namespace/nickname mappings in AllegroGraph.</p>
<p>When we execute our SPARQL query, it matches the "Alice" within the literal "Alice B. Toklas" because that literal occurs in a triple having the registered <strong>fullname</strong> predicate, but it does not match the "Alice" in the literal "Alice in Wonderland" because the <strong>booktitle</strong> predicate was not registered for text indexing. This query returns <em>all triples</em> of a resource that had a successful match in at least one object value. </p>
<pre class="input">        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult result = (TupleQueryResult)tupleQuery.evaluate();<br>        int count = 0;<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            if (count &lt; 5) {<br>                println(bindingSet);<br>            }<br>            count += 1;<br>        }</pre>
<p>The output of this loop is:</p>
<pre class="output">Whole-word match for 'Alice'.<br>[s=http://example.org/people/alice1;p=http://example.org/people/fullname;o="Alice B. Toklas"]<br>[s=http://example.org/people/alice1;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/people/Person]</pre>
<p>The text index supports simple wildcard queries. The asterisk (*) may be appended to the end of the pattern to indicate "any number of additional characters." For instance, this query looks for whole words that begin with "Ali":</p>
<pre class="input">        queryString = <br>        	"SELECT ?s ?p ?o " +<br>        	"WHERE { ?s ?p ?o . ?s fti:match 'Ali*' . }";</pre>
<p>It finds the same two triples as before.</p>
<p>There is also a single-character wildcard, the question mark.  You can add as many question marks as you need to the string pattern.  This query looks for a five-letter word that has "l" in the second position and "c" in the fourth position:</p>
<pre class="input">        queryString = <br>        	"SELECT ?s ?p ?o " +<br>        	"WHERE { ?s ?p ?o . ?s fti:match '?l?c?' . }";</pre>
<p>This query finds the same two triples as before. </p>
<p>This time we'll do something a little different.  The free text indexing matches whole words only, even when using wildcards. What if you really need to match a substring in a word of unknown length? You can write a SPARQL query that performs a <strong>regex </strong>match against object values. This can be inefficient compared to indexed search, and the match is not confined to the registered free-text predicates. The following query looks for the substring "lic" in all literal object values:</p>
<pre class="input">        queryString = <br>        	"SELECT ?s ?p ?o " +<br>        	"WHERE { ?s ?p ?o . FILTER regex(?o, \"lic\") }";</pre>
<p>This query returns two triples, but they are not quite the same as before:</p>
<pre class="output">Substring match for 'lic'.<br>[s=http://example.org/people/alice1;p=http://example.org/people/fullname;o="Alice B. Toklas"]<br>[s=http://example.org/people/book1;p=http://example.org/people/title;o="Alice in Wonderland"]</pre>
<p>As you can see, the regex match found "lic" in "Alice in Wonderland," which was not a registered free-text predicate. It made this match by doing a string comparison against every object value in the triple store. Even though you can streamline the SPARQL query considerably by writing more restrictive patterns, this is still inherently less efficient than using the indexed approach. </p>
<h2 id="Ask, Describe, Construct and Update Queries">Ask, Describe, Construct, and Update Queries (example13())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>SPARQL provides alternatives to the standard SELECT query. Example example13() exercises these alternatives to show how AllegroGraph Server handles them. </p>

<ul>
  <li> SELECT: Returns variables bound in a query pattern match. </li>
  <li>ASK: Returns a boolean indicating whether a query matches or not. </li>
  <li>CONSTRUCT: Returns triples constructed by substituting variables in a set of triple templates. </li>
  <li>DESCRIBE: Returns all of the triples of a matching resource. </li>
  <li>Update: Evaluates <a href="http://www.w3.org/TR/sparql11-update/">SPARQL Update</a> queries to modify the repository. </li>
</ul>
<p>The example begins by borrowing a connection object from example6(). This connects to a repository that contains vcard and Kennedy data. We'll need to register a Kennedy namespace to make the queries easier to read. 
<pre class="input">    public static void example13 () throws Exception {<br>        RepositoryConnection conn = example6();<br>        conn.setNamespace("kdy", "http://www.franz.com/simple#");</pre>
<p>As it happens, we don't need the vcard data this time, so we'll remove it. This is an example of how to delete an entire subgraph (the vcards "context"):</p>
<pre class=input>        ValueFactory vf = conn.getValueFactory();<br>        URI context = vf.createURI("http://example.org#vcards");<br>        conn.remove((Resource)null, (URI)null, (Value)null, context);</pre>
<p>The example begins with a SELECT query so we can see some of the Kennedy resources. </p>
<pre class="input">        String queryString = "select ?s where { ?s rdf:type kdy:person} limit 5";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();<br>        println("\nSELECT some persons:");<br>        while (result.hasNext()) {<br>            println(result.next());<br>        }</pre>
Note that SELECT returns variable bindings. In this case it returns subject URIs of five people:
<pre class="output">SELECT some persons:<br>[s=http://www.franz.com/simple#person1]<br>[s=http://www.franz.com/simple#person2]<br>[s=http://www.franz.com/simple#person3]<br>[s=http://www.franz.com/simple#person4]<br>[s=http://www.franz.com/simple#person5]</pre>
<p>The ASK query returns a Boolean, depending on whether the triple pattern matched any triples. In this case we ran two tests; one seeking "John" and the other looking for "Alice." Note that the ASK query uses a different construction method than the SELECT query:<strong> prepareBooleanQuery()</strong>. </p>
<pre class="input">        queryString = "ask { ?s kdy:first-name 'John' } ";<br>        BooleanQuery booleanQuery = conn.prepareBooleanQuery(QueryLanguage.SPARQL, queryString);<br>        boolean truth = booleanQuery.evaluate(); <br>        println("\nASK: Is there anyone named John? " + truth);<br>
        queryString = "ask { ?s kdy:first-name 'Alice' } ";<br>        BooleanQuery booleanQuery2 = conn.prepareBooleanQuery(QueryLanguage.SPARQL, queryString);<br>        boolean truth2 = booleanQuery2.evaluate(); <br>        println("\nASK: Is there anyone named Alice? " + truth2);</pre>
<p>The output of this loop is:</p>
<pre class="output">ASK: Is there anyone named John? true
ASK: Is there anyone named Alice? false</pre>
<p>The CONSTRUCT query contructs a statement object out of the matching values in the triple pattern. A "statement" is a client-side triple. Construction queries use <strong>prepareGraphQuery()</strong>. The point is that the query can bind variables from existing triples and then "construct" a<em> new triple</em> by recombining the values. This query constructs new triples using a <strong>kdy:has-grandchild</strong> predicate. </p>
<pre class="input">        queryString = "construct {?a kdy:has-grandchild ?c}" + <br>	                  "    where { ?a kdy:has-child ?b . " +<br>	                  "            ?b kdy:has-child ?c . }";<br>        AGGraphQuery constructQuery = conn.prepareGraphQuery(QueryLanguage.SPARQL, queryString);<br>        GraphQueryResult gresult = constructQuery.evaluate(); ; </pre>
<p>The CONSTRUCT query does not actually add the new triples to the store. You have to iterate through the results and add them yourself: </p>
<pre class="input">        while (gresult.hasNext()) {<br>            conn.add(gresult.next());  // adding new triples to the store<br>        }</pre>
<p>As with SELECT queries, it is possible to request just the number of results of a CONSTRUCT query using the AGGraphQuery#count() method. </p>
<pre class="input">
        // Just the count now.  The count is done server-side,
        // and only the count is returned.
        long count = constructQuery.count();
        println("count: " + count);
</pre>
<p>The DESCRIBE query returns a "graph," meaning all triples of the matching resources. It uses <strong>prepareGraphQuery()</strong>. In this case we asked SPARQL to describe one grandparent and one grandchild. (This confirms that the kdy:has-grandchild triples successfully entered the triple store.) </p>
<pre class="input">        queryString = "describe ?s ?o where { ?s kdy:has-grandchild ?o . } limit 1";<br>        GraphQuery describeQuery = conn.prepareGraphQuery(QueryLanguage.SPARQL, queryString);<br>        gresult = describeQuery.evaluate(); <br>        println("\nDescribe one grandparent and one grandchild:");<br>        while (gresult.hasNext()) {<br>            println(gresult.next());<br>        }</pre>
<p>The output of this loop is lengthy, because the Kennedy resources have many triples. One block of triples looked like this, showing the new has-grandchild triples: </p>
<pre class="output">(http://www.franz.com/simple#person1, http://www.franz.com/simple#has-grandchild, http://www.franz.com/simple#person20)<br>(http://www.franz.com/simple#person1, http://www.franz.com/simple#has-grandchild, http://www.franz.com/simple#person22)<br>(http://www.franz.com/simple#person1, http://www.franz.com/simple#has-grandchild, http://www.franz.com/simple#person24)<br>(http://www.franz.com/simple#person1, http://www.franz.com/simple#has-grandchild, http://www.franz.com/simple#person25)<br>(http://www.franz.com/simple#person1, http://www.franz.com/simple#has-grandchild, http://www.franz.com/simple#person26)<br>
</pre>
<p><a href="http://www.w3.org/TR/sparql11-update/">SPARQL Update</a> queries can also be evaluated to modify the repository.  A SPARQL Update can be executed as follows:</p>
<pre class="input">
        updateString = "PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt; \n"
        	+ "DELETE DATA { GRAPH &lt;http://example/bookStore&gt; { &lt;http://example/book1&gt;  dc:title  \"Fundamentals of Compiler Desing\" } } ; \n"
        	+ "\n"
        	+ "PREFIX dc: &lt;http://purl.org/dc/elements/1.1/&gt; \n"
        	+ "INSERT DATA { GRAPH &lt;http://example/bookStore&gt; { &lt;http://example/book1&gt;  dc:title  \"Fundamentals of Compiler Design\" } }";

        println("\nPerforming a sequence of SPARQL Updates in one request (to correct the title):\n" + queryString);
        conn.prepareUpdate(QueryLanguage.SPARQL, updateString).execute();
</pre>
AG also allows SPARQL Updates to be evaluated using a BooleanQuery (for side effect, ignoring the result) as follows:
<pre class="input">
        conn.prepareBooleanQuery(QueryLanguage.SPARQL, updateString).evaluate();
</pre>
 
<h2 id="Parametric Queries">Parametric Queries (example14())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
 <p>The Java Sesame API to AllegroGraph Server lets you set up a <strong>parameteric</strong> query and then set the values of some query parameters prior to evaluation; this approach is stylistically cleaner and can be more efficient than building up custom query strings for each of the different bindings.  There's also a potential performance benefit to parsing/compiling a query only once during query preparation, rather than during each query evaluation; while parsing/compilation overhead is often neglible, we recommend adopting the style in this example in order to make the most of any future improvements in query preparation.</p>
 <p>In <strong>example14()</strong> we set up resources for Alice and Bob, and then prepare a parametric SPARQL query to retrieve the triples.  Evaluating this query would normally find all four triples, but by binding the subject value ahead of time, we can retrieve the "Alice" triples separately from the "Bob" triples.</p>
 <p>The example begins by borrowing a connection object from example2(). This means there are already Bob and Alice resources in the repository. We do need to recreate the URIs for the two resources, however. </p>
 <pre class="input">    public static void example14() throws Exception {<br>        RepositoryConnection conn = example2(false);<br>        ValueFactory f = conn.getValueFactory();<br>        URI alice = f.createURI("http://example.org/people/alice");<br>        URI bob = f.createURI("http://example.org/people/bob");</pre>
<p>The SPARQL query is the simple, unconstrained query that returns all triples. We use <strong>prepareTupleQuery()</strong> to create the query object. </p>
<pre class="input">        String queryString = "select ?s ?p ?o where { ?s ?p ?o} ";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);</pre>
<p>Before evaluating the query, however, we'll use the query object's <strong>setBinding()</strong> method to assign Alice's URI to the "s" variable in the query. This means that all matching triples are required to have Alice's URI in the subject position of the triple. </p>
<pre class="input">        tupleQuery.setBinding("s", alice);<br>        TupleQueryResult result = tupleQuery.evaluate();<br>        println("\nFacts about Alice:");            <br>        while (result.hasNext()) {<br>            println(result.next());<br>        }<br>        result.close();</pre>
<p>The output of this loop consists of all triples whose subject is Alice:</p>
<pre class="output">Facts about Alice:<br>[s=http://example.org/people/alice;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]<br>[s=http://example.org/people/alice;p=http://example.org/ontology/name;o="Alice"]</pre>
<p>Now we'll run the same query again, but this time we'll constrain "s" to be Bob's URI. The query will return all triples whose subject is Bob. </p>
<pre class="input">        tupleQuery.setBinding("s", bob);<br>        println("\nFacts about Bob:");    <br>        result = tupleQuery.evaluate();<br>        while (result.hasNext()) {<br>            println(result.next());<br>        }<br>        result.close();<br>        conn.close();</pre>
 The output of this loop is:
 <pre class="output">Facts about Bob:<br>[s=http://example.org/people/bob;p=http://example.org/ontology/name;o="Bob"]<br>[s=http://example.org/people/bob;p=http://www.w3.org/1999/02/22-rdf-syntax-ns#type;o=http://example.org/ontology/Person]</pre>
 <h2 id="Range Matches">Range Matches (example15())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
 <p>Example example15() demonstrates how to set up a query that matches a range of values. In this case, we'll retrieve all people between 30 and 50 years old (inclusive). We can accomplish this using a SPARQL query to take advantage of AllegroGraph's automatic typing of literal values. </p>
 <p>This example begins by getting a connection object from example1(), and then clearing the repository of the existing triples. </p>
 <pre class="input">    public static void example15() throws Exception {<br>        println("Starting example example15().");<br>        AGRepositoryConnection conn = example1(false);<br>        ValueFactory f = conn.getValueFactory();<br>        conn.clear();</pre>
<p>Then we register a namespace to use in the query. </p>
<pre class="input">        String exns = "http://example.org/people/";<br>        conn.setNamespace("ex", exns);</pre>
<p>Next we need to set up the URIs for Alice, Bob, Carol and the predicate "age". </p>
<pre class="input">        URI alice = f.createURI(exns, "alice");<br>        URI bob = f.createURI(exns, "bob");<br>        URI carol = f.createURI(exns, "carol");    <br>        URI age = f.createURI(exns, "age");    </pre>
<p>The next step is to create age triples for the three people. Notice that the values are inconsistent. One is an integer; one is a float; and one is a number in a string. Good programming would require more consistency here, but real-world data often breaks the rules. </p>
<pre class="input">        conn.add(alice, age, f.createLiteral(42));<br>        conn.add(bob, age, f.createLiteral(45.1));<br>        conn.add(carol, age, f.createLiteral("39"));</pre>
<p>AllegroGraph's internal datatype mapping automatically transforms 42 into an XMLSchema#int, and 45.1 into an XMLSchema#double. The string, however, is treated as a literal string value. </p>
<p>The next step is to use SPARQL to retrieve all triples where the age value is between 30 and 50. Note that the literal numbers 30 and 50 are converted internally to integers, but the test also permits floats (doubles) to match, too. </p>
<pre class="input">        println("\nRange query for integers and floats.");<br>        String queryString = <br>        	"SELECT ?s ?p ?o  " +<br>        	"WHERE { ?s ?p ?o . " +<br>        	"FILTER ((?o &gt;= 30) &amp;&amp; (?o &lt;= 50)) }";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();</pre>
<p>The result object contains:</p>
<pre class="output">Range query for integers and floats.<br>http://example.org/people/alice http://example.org/people/age "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;<br>http://example.org/people/bob http://example.org/people/age "45.1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;</pre>
<p>It has matched 42 and 45.1, but not "39". </p>
<p>What if we want to pick up the odd values that were created as strings? SPARQL lets us cast the triple's object value as an integer before making the test. That query looks like this:</p>
<pre class="input">         String queryString = 
         "PREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; " +
         "SELECT ?s ?p ?o " +
         "WHERE { ?s ?p ?o . " +
         "FILTER ((xsd:integer(?o) &gt;= 30) &amp;&amp; (xsd:integer(?o) &lt;= 50)) }";</pre>

<p>Note that we had to add a PREFIX line to accommodate the xsd: namespace. The <strong>xsd:integer(?o)</strong> element takes the current object value and attempts to coerce it to be an integer. If successful, the test goes forward.</p>
<p>The output of this query is:</p>
<pre class="output">Range query for integers, floats, and integers in strings.
http://example.org/people/alice http://example.org/people/age "42"^^&lt;http://www.w3.org/2001/XMLSchema#int&gt;
http://example.org/people/bob http://example.org/people/age "45.1"^^&lt;http://www.w3.org/2001/XMLSchema#double&gt;
http://example.org/people/carol http://example.org/people/age "39"  </pre>
<p>This query picked up integer, double, and string values. </p>
<h2 id="Federated Repositories">Federated Repositories (example16())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>AllegroGraph lets you split up your triples among repositories on multiple servers and then search them all in parallel. To do this we query a single "federated" repository that automatically distributes the queries to the secondary repositories and combines the results. From the point of view of your Java code, it looks like you are working with a single repository. </p>
<p>This example begins by defining a small output function that we'll use at the end of the lesson. It prints out responses from different repositories. This example is about red apples and green apples, so the output function talks about apples. </p>
<pre class="input">    private static void pt(String kind, TupleQueryResult rows) throws Exception {<br>        println("\n" + kind + " Apples:\t");<br>        while (rows.hasNext()) {<br>            println(rows.next());<br>        }<br>        rows.close();<br>    }</pre>
<p>In example16(), we open connections to a redRepository and a greenRepository on the local server. In a typical federation scenario, these respositories would be distributed across multiple servers. We begin with the connection object from example6(), and then climb the object tree to obtain its catalog. </p>
<pre class="input">    public static void example16() throws Exception {<br>        AGRepositoryConnection conn = example6();<br>        AGRepository myRepository = conn.getRepository();<br>        AGCatalog catalog = myRepository.getCatalog();</pre>
<p>The next few lines establish a "red" repository in the catalog. </p>
<pre class="input">        AGRepository redRepo = catalog.createRepository("redthingsjv");<br>        redRepo.initialize();<br>        RepositoryConnection redConn = redRepo.getConnection();
		closeBeforeExit(redConn);<br>        redConn.clear();<br>        ValueFactory rf = redConn.getValueFactory();</pre>
<p>Followed by a "green" repository. </p>
<pre class="input">        AGRepository greenRepo = catalog.createRepository("greenthingsjv");<br>        greenRepo.initialize();<br>        RepositoryConnection greenConn = greenRepo.getConnection();
		closeBeforeExit(greenConn);<br>        greenConn.clear();<br>        ValueFactory gf = greenConn.getValueFactory();</pre>
<p>Now we create a "federated" repository, which is connected to the distributed repositories at the back end. First we have to obtain the server object because the server supplies the <strong>federate() </strong>method. </p>
<pre class="input">
        AGServer server = myRepository.getCatalog().getServer();<br>        AGAbstractRepository rainbowRepo = server.federate(redRepo, greenRepo);<br><br>        rainbowRepo.initialize();<br>        AGRepositoryConnection rainbowConn = rainbowRepo.getConnection();
		closeBeforeExit(rainbowConn);</pre>
<p>The next step is to populate the Red and Green repositories with a few triples. Notice that we have two red apples, a green apple, and a famous frog. </p>
<pre class="input">        String ex = "http://example.org/";<br>        // add a few triples to the red and green stores:<br>        redConn.add(rf.createURI(ex+"mcintosh"), RDF.TYPE, rf.createURI(ex+"Apple"));<br>        redConn.add(rf.createURI(ex+"reddelicious"), RDF.TYPE, rf.createURI(ex+"Apple"));    <br>        greenConn.add(gf.createURI(ex+"pippin"), RDF.TYPE, gf.createURI(ex+"Apple"));<br>        greenConn.add(gf.createURI(ex+"kermitthefrog"), RDF.TYPE, gf.createURI(ex+"Frog"));</pre>
<p>It is necessary to register the "ex" namespace in all three repositories so we can use it in the upcoming query. </p>
<pre class="input">        redConn.setNamespace("ex", ex);<br>        greenConn.setNamespace("ex", ex);<br>        rainbowConn.setNamespace("ex", ex);</pre>
<p>Now we write a query that retrieves Apples from the Red repository, the Green repository, and the federated repository, and prints out the results. </p>
<pre class="input">        String queryString = "select ?s where { ?s rdf:type ex:Apple }";<br>        // query each of the stores; observe that the federated one is the union of the other two:<br>        pt("red", redConn.prepareTupleQuery(QueryLanguage.SPARQL, queryString).evaluate());<br>        pt("green", greenConn.prepareTupleQuery(QueryLanguage.SPARQL, queryString).evaluate());<br>        pt("federated", rainbowConn.prepareTupleQuery(QueryLanguage.SPARQL, queryString).evaluate());<br>    }</pre>
<p>The output is shown below. The federated response combines the individual responses. (There are no frogs.) </p>
<pre class="output">Red Apples:	<br>[s=http://example.org/reddelicious]<br>[s=http://example.org/mcintosh]<br>
Green Apples: <br>[s=http://example.org/pippin]<br>
Federated Apples: <br>[s=http://example.org/reddelicious]<br>[s=http://example.org/mcintosh]<br>[s=http://example.org/pippin]</pre>
<h2 id="Prolog Rule Queries">Prolog Rule Queries (example17())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>AllegroGraph Server lets us load Prolog backward-chaining rules to make query-writing simpler.&nbsp; The Prolog rules let us write the queries in terms of higher-level concepts.&nbsp; When a query refers to one of these concepts, Prolog rules become active in the background to determine if the concept is valid in the current context.&nbsp; </p>
<p>For instance, in this example the query says that the matching resource must be a "man".&nbsp; A Prolog rule examines the matching resources to see which of them are persons who are male.&nbsp; The query can proceed for those resources. The rules provide a level of abstraction that makes the queries simpler to express. </p>
<p>The example17() begins by borrowing a connection object from example6(), which contains the Kennedy family tree.</p>
<pre class="input">    public static void example17() throws Exception {<br>        AGRepositoryConnection conn = example6(false);</pre>
<p>We will need the same namespace as we used in the Kennedy example. </p>
<pre class="input">        conn.setNamespace("kdy", "http://www.franz.com/simple#");</pre>
<p>These are the "man" and "woman" rules.&nbsp; A resource represents a "woman" if the resource contains a sex = female triple and an rdf:type = person triple.&nbsp; A similar deduction identifies a "man".&nbsp; The "q" at the beginning of each pattern simply stands for "query" and introduces a triple pattern. </p>
<pre class="input">        String rules1 =<br>            "(&lt;-- (woman ?person) ;; IF\n" +<br>            "     (q ?person !kdy:sex !kdy:female)\n" +<br>            "     (q ?person !rdf:type !kdy:person))\n" +<br>            "(&lt;-- (man ?person) ;; IF\n" +<br>            "     (q ?person !kdy:sex !kdy:male)\n" +<br>            "     (q ?person !rdf:type !kdy:person))";</pre>
<p>The rules must be explicitly added to the connection. </p>
<pre class="input">        conn.addRules(rules1);
</pre>
<p>Note that addRules automatically converts the connection to a "dedicated" session for the rules to operate in; rules cannot be loaded into the AllegroGraph common back end.</p>
<p>This is the query.&nbsp; This query locates all the "man" resources, and retrieves their first and last names. </p>
<pre class="input">        String queryString =<br>            "(select (?first ?last)\n" +<br>            "        (man ?person)\n" +<br>            "        (q ?person !kdy:first-name ?first)\n" +<br>            "        (q ?person !kdy:last-name ?last))";</pre>
<p>Here we perform the query and retrieve the result object.&nbsp; </p>
<pre class="input">        TupleQuery tupleQuery = conn.prepareTupleQuery(AGQueryLanguage.PROLOG, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();</pre>
<p>The result object contains multiple bindingSets.&nbsp; We can iterate over them to print out the values. </p>
<pre class="input">        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            Value f = bindingSet.getValue("first");<br>            Value l = bindingSet.getValue("last");<br>            println(f.stringValue() + " " + l.stringValue());<br>        }<br>        result.close();</pre>
<p>The output contains many names; there are just a few of them. </p>
<pre class="output">Robert Kennedy<br>Alfred Tucker<br>Arnold Schwarzenegger<br>Paul Hill<br>John Kennedy</pre>
<p>&nbsp;</p>

<h2 id="Loading Prolog Rules">Loading Prolog Rules (example18())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>Example <strong>example18()</strong> demonstrates how to load a file of Prolog rules into the Java Sesame API of AllegroGraph Server.&nbsp; It also demonstrates how robust a rule-augmented system can become.&nbsp; The domain is the Kennedy family tree again, borrowed from example6().&nbsp; After loading a file of rules (<strong>java_rules.txt</strong>), we'll pose a simple query.&nbsp; The query asks AllegroGraph to list all the uncles in the family tree, along with each of their nieces or nephews.&nbsp; This is the query:</p>
<pre class="input">(select (?ufirst ?ulast ?cfirst ?clast)<br>        (uncle ?uncle ?child)<br>        (name ?uncle ?ufirst ?ulast)<br>        (name ?child ?cfirst ?clast))</pre>
<p>The problem is that the triple store contains no information about uncles.&nbsp; The rules will have to deduce this relationship by finding paths across the RDF graph.</p>
<p>What's an "uncle," then?&nbsp; Here's a rule that can recognize uncles:</p>
<pre class="input">(&lt;-- (uncle ?uncle ?child) <br>    (man ?uncle)<br>    (parent ?grandparent ?uncle)<br>    (parent ?grandparent ?siblingOfUncle)<br>    (not (= ?uncle ?siblingOfUncle))<br>    (parent ?siblingOfUncle ?child))</pre>
<p>The rule says that an "uncle" is a "man" who has a sibling who is the "parent" of a child.&nbsp; (Rules like this always check to be sure that the two nominated siblings are not the same resource.) Note that none of these relationships directly match triples in the repository. They all deal in higher-order concepts. We'll need additional rules to determine what a "man" is, and what a "parent" is.</p>
<p>What is a "parent?" It turns out that there are two ways to be classified as a parent:</p>
<pre class="input">(&lt;-- (parent ?father ?child)<br>    (father ?father ?child))

(&lt;-- (parent ?mother ?child)<br>    (mother ?mother ?child))</pre>
<p>A person is a "parent" if a person is a "father."&nbsp; Similarly, a person is a "parent" if a person is a "mother." </p>
<p>What's a "father?"</p>
<pre class="input">(&lt;-- (father ?parent ?child)<br>    (man ?parent)<br>    (q ?parent !rltv:has-child ?child))</pre>
<p>A person is a "father" if the person is "man" and has a child. &nbsp; The final pattern (starting with "q") is a triple match from the Kennedy family tree.</p>
<p>What's a "man?"</p>
<pre class="input">(&lt;-- (man ?person)<br>    (q ?person !rltv:sex !rltv:male)<br>    (q ?person !rdf:type !rltv:person))</pre>
<p>A "man" is a person who is male.&nbsp; These patterns both match triples in the repository.&nbsp; </p>
<p>The<strong> java_rules.txt</strong> file contains many more Prolog rules describing relationships, including transitive relationships like "ancestor" and "descendant." Please examine this file for more ideas about how to use rules with AllegroGraph. </p>
<p>The <strong>example18()</strong> example begins by borrowing a connection object from example6(), which means the Kennedy family tree is already loaded into the repository, and we are dealing with a <a href="#Transaction">transaction session</a>. &nbsp; </p>
<pre class="input">    public static void example18() throws Exception {<br>        AGRepositoryConnection conn = example6(false);</pre>
<p>We need these two namespaces because they are used in the query and in the file of rules. </p>
<pre class="input">        conn.setNamespace("kdy", "http://www.franz.com/simple#");<br>        conn.setNamespace("rltv", "http://www.franz.com/simple#");</pre>
<!-- <p>We need to tell AllegroGraph Server which query syntax to expect. </p>
<pre class="input">
    conn.setRuleLanguage(QueryLanguage.PROLOG)</pre> 
	-->
<p>The next step is to load the rule file. Note that you might have to edit the file path, depending on your platform and installation. </p>
<pre class="input">
        File path = new File(DATA_DIR, "java_rules.txt");
        try (InputStream is = new FileInputStream(path)) {
            conn.addRules(is);
        }
</pre>
<p>The query asks for the full name of each uncle and each niece/nephew.&nbsp; (The (name ?x ?fullname) relationship used in the query is provided by yet another Prolog rule, which concatenates a person's first and last names into a single string.) </p>
<pre class="input">        String queryString = <br>        	"(select (?ufirst ?ulast ?cfirst ?clast)" +<br>                     "(uncle ?uncle ?child)" +<br>                     "(name ?uncle ?ufirst ?ulast)" +<br>                     "(name ?child ?cfirst ?clast))";</pre>
<p>Here we execute the query and display the results:</p>
<pre class="input">        TupleQuery tupleQuery = conn.prepareTupleQuery(AGQueryLanguage.PROLOG, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();     <br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            Value u1 = bindingSet.getValue("ufirst");<br>            Value u2 = bindingSet.getValue("ulast");<br>            String ufull = u1.stringValue() + " " + u2.stringValue() ;<br>            Value c1 = bindingSet.getValue("cfirst");<br>            Value c2 = bindingSet.getValue("clast");<br>            String cfull = c1.stringValue() + " " + c2.stringValue() ;<br>            println(ufull + " is the uncle of " + cfull);</pre>
<p>The code is a little more complicated than normal because of the string concatenations that build the names. 
<p>The output of this loop (in part) looks like this:
<pre class="output">Robert Kennedy is the uncle of Amanda Smith.<br>Robert Kennedy is the uncle of Kym Smith.<br>Edward Kennedy is the uncle of Robert Shriver.<br>Edward Kennedy is the uncle of Maria Shriver.<br>Edward Kennedy is the uncle of Timothy Shriver.</pre>
<p>As before, it is good form to free the connection and the result object when you are finished with them.</p>
<pre class="input">        result.close();<br>        conn.close();</pre>

<h2 id="RDFS++ Inference">RDFS++ Inference (example19())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>The great promise of the semantic web is that we can use RDF metadata to combine information from multiple sources into a single, common model.&nbsp; The great problem of the semantic web is that it is so difficult to recognize when two resource descriptions from different sources actually represent the same thing.&nbsp; This problem arises because there is no uniform or universal way to generate URIs identifying resources.&nbsp; As a result, we may create two resources, Bob and Robert, that actually represent the same person. </p>
<p>This problem has generated much creativity in the field. One way to approach the problem is through inference.&nbsp; There are certain relationships and circumstances where an inference engine can deduce that two resource descriptions actually represent one thing, and then automatically merge the descriptions.&nbsp; AllegroGraph's <a href="../reasoner-tutorial.html">inference engine</a> can be turned on or off each time you run a query against the triple store.&nbsp; (Note that inference is turned off by default, which is the opposite of standard RDF4J behavior.) </p>
<p>In example example19(), we will create four resources: Bob, with son Bobby, and Robert with daughter Roberta.&nbsp; </p>
<p><img src="inferenceSetup.jpg" width="448" height="101"></p>
<p>First we have to set up the data. We begin by generating four URIs for the new resources. </p>
<pre class="input">    public static void example19() throws Exception {<br>        AGRepositoryConnection conn = example1(false);<br>        ValueFactory f = conn.getValueFactory();<br>        URI robert = f.createURI("http://example.org/people/robert");<br>        URI roberta = f.createURI("http://example.org/people/roberta");<br>        URI bob = f.createURI("http://example.org/people/bob");<br>        URI bobby = f.createURI("http://example.org/people/bobby");</pre>
The next step is to create URIs for the predicates we'll need (<em>name</em> and <em>fatherOf</em>), plus one for the Person class. <br>
<pre class="input">        URI name = f.createURI("http://example.org/ontology/name");<br>        URI fatherOf = f.createURI("http://example.org/ontology/fatherOf");<br>        URI person = f.createURI("http://example.org/ontology/Person");</pre>
The names of the four people will be literal values. <br>
<pre class="input">        Literal bobsName = f.createLiteral("Bob");<br>        Literal bobbysName = f.createLiteral("Bobby");<br>        Literal robertsName = f.createLiteral("Robert");<br>        Literal robertasName = f.createLiteral("Roberta");</pre>
<p>Robert, Bob and the children are all instances of class Person.&nbsp; It is good practice to identify all resources by an rdf:type link to a class.</p>
<pre class="input">        conn.add(robert, RDF.TYPE, person);<br>        conn.add(roberta, RDF.TYPE, person);<br>        conn.add(bob, RDF.TYPE, person);<br>        conn.add(bobby, RDF.TYPE, person);</pre>
The four people all have literal names. <br>
<pre class="input">        conn.add(robert, name, robertsName);<br>        conn.add(roberta, name, robertasName);<br>        conn.add(bob, name, bobsName);<br>        conn.add(bobby, name, bobbysName);</pre> 
Robert and Bob have links to the child resources:
<br>
<pre class="input">        // robert has a child<br>        conn.add(robert, fatherOf, roberta);<br>        // bob has a child<br>        conn.add(bob, fatherOf, bobby);</pre> 
<h3>SameAs, using a SPARQL Query </h3>
<p>Now that the basic resources and relations are in place, we'll seed the triple store with a statement that "Robert is the same as Bob," using the <strong>owl:sameAs</strong> predicate.&nbsp; The AllegroGraph inference engine recognizes the semantics of owl:sameAs, and automatically infers that Bob and Robert share the same attributes.&nbsp; Each of them originally had one child.&nbsp; When inference is turned on, however, they each have two children.&nbsp; </p>
<p><img src="inferenceSaveAs.jpg" width="459" height="182"></p>
<p>Note that SameAs does not combine the two resources.&nbsp; Instead it links each of the two resources to all of the combined children.&nbsp; The red links in the image are "inferred" triples.&nbsp; They have been deduced to be true, but are not actually present in the triple store. </p>
<p>This is the critical link that tells the inference engine to regard Bob and Robert as the same resource. </p>
<pre class="input">        conn.add(bob, OWL.SAMEAS, robert);</pre>
This is a simple SPARQL query asking for the children of Robert, with inference turned OFF. Note the use of <strong>tupleQuery.setIncludeInferred()</strong>, which controls whether or not inferred triples may be included in the query results. Inference is turned off by default, but for teaching purposes we have turned it of explicitly. We also took the liberty of setting variable bindings for ?robert and ?fatherOf, simply to make the code easier to read. Otherwise we would have had to put full-length URIs in the query string. <br>
<pre class="input">        String queryString = <strong>"SELECT ?child WHERE {?robert ?fatherOf ?child .}";</strong><br>        TupleQuery tupleQuery = conn.prepareTupleQuery(QueryLanguage.SPARQL, queryString);<br>        <strong>tupleQuery.setIncludeInferred(false); </strong> // Turn off inference<br>        tupleQuery.setBinding("robert", robert);<br>        tupleQuery.setBinding("fatherOf", fatherOf);<br>        TupleQueryResult result = tupleQuery.evaluate();<br>        println("\nChildren of Robert, inference OFF");            <br>        while (result.hasNext()) {<br>            println(result.next());
        }</pre> 
<p>The search returns one triple, which is the link from Robert to his direct child, Roberta. </p>
<pre class="output">Children of Robert, inference OFF<br>[child=http://example.org/people/roberta]</pre>
<p>Now we'll perform the same query (the same tupleQuery, in fact), with inference turned ON.</p>
<pre class="input">        <strong>tupleQuery.setIncludeInferred(true);</strong>  // Turn on inference<br>        TupleQueryResult result2 = tupleQuery.evaluate();<br>        println("\nChildren of Robert, inference ON");            <br>        while (result2.hasNext()) {<br>            println(result2.next());<br>        }</pre>
<pre class="output">Children of Robert, inference ON<br>[child=http://example.org/people/roberta]<br>[child=http://example.org/people/bobby]</pre>
<p>Note that with inference ON, Robert suddenly has two children because Bob's child has been included.&nbsp; Also note that the final triple (robert fatherOf bobby) has been inferred.&nbsp; The inference engine has determined that this triple logically must be true, even though it does not appear in the repository. </p>
<h3>InverseOf</h3>
<p>We can reuse the Robert family tree to see how the inference engine can deduce the presence of inverse relationships. </p>
<p>Up to this point in this tutorial, we have created new predicates simply by creating a URI and using it in the predicate position of a triple.&nbsp; This time we need to create a predicate<em> resource</em> so we can set an attribute of that resource.&nbsp; We're going to declare that the <strong>hasFather</strong> predicate is the <strong>owl:inverseOf</strong> the existing fatherOf predicate. </p>
<p>The first step is to remove the owl:sameAs link, because we are done with it. </p>
<pre class="input">        conn.remove(bob, OWL.SAMEAS, robert);</pre>
<p>We'll need a URI for the new hasFather predicate:</p>

<pre class="input">        URI hasFather = f.createURI("http://example.org/ontology/hasFather");</pre>
<p>This is the line where we create a predicate resource.&nbsp; It is just a triple that describes a property of the predicate.&nbsp; The hasFather predicate is the inverse of the fatherOf predicate: </p>

<pre class="input">        conn.add(hasFather, OWL.INVERSEOF, fatherOf);</pre>
<p>First, we'll search for hasFather triples, leaving inference OFF to show that there are no such triples in the repository: </p>

<pre class="input">        println("\nPeople with fathers, inference OFF");<br>        printRows( conn.getStatements(null, hasFather, null, false) );</pre>
<pre class="output">People with fathers, inference OFF<br></pre>
<p>Now we'll turn inference ON.&nbsp; This time, the AllegroGraph inference engine discovers two "new" hasFather triples. </p>
<pre class="input">        println("\nPeople with fathers, inference ON");<br>        printRows( conn.getStatements(null, hasFather, null, true) );</pre>
<pre class="output">People with fathers, inference ON<br>(http://example.org/people/roberta, http://example.org/ontology/hasFather, http://example.org/people/robert) [null]<br>(http://example.org/people/bobby, http://example.org/ontology/hasFather, http://example.org/people/bob) [null]</pre>
<p>Both of these triples are inferred by the inference engine.</p>
<h3>SubPropertyOf</h3>
<p>Invoking inference using the <strong>rdfs:subPropertyO</strong>f predicate lets us "combine" two predicates so they can be searched as one.&nbsp; For instance, in our Robert/Bob example, we have explicit fatherOf relations.&nbsp; Suppose there were other resources that used a parentOf relation instead of fatherOf.&nbsp; By making fatherOf a subproperty of parentOf, we can search for parentOf triples and automatically find the fatherOf triples at the same time. </p>
<p>First we should remove the owl:inverseOf relation from the previous example. We don't have to, but it keeps things simple. </p>
<pre class="input">       conn.remove(bob, OWL.SAMEAS, robert);</pre>
<p>We'll need a parentOf URI to use as the new predicate.&nbsp; Then we'll add a triple saying that fatherOf is an rdfs:subPropertyOf the new predicate, parentOf:</p>
<pre class="input">        URI parentOf = f.createURI("http://example.org/ontology/parentOf");<br>        conn.add(fatherOf, RDFS.SUBPROPERTYOF, parentOf);</pre>
<p>If we now search for parentOf triples with inference OFF, we won't find any. No such triples exist in the repository. </p>
<pre class="input">        println("\nPeople with parents, inference OFF");<br>        printRows( conn.getStatements(null, parentOf, null, false) );</pre>
<pre class="output">People with parents, inference OFF

</pre>
<p>With inference ON, however, AllegroGraph infers two new triples: </p>
<pre class="input">        println("\nPeople with parents, inference ON");<br>        printRows( conn.getStatements(null, parentOf, null, true) );</pre>
<pre class="output">People with parents, inference ON<br>(http://example.org/people/robert, http://example.org/ontology/parentOf, http://example.org/people/roberta) [null]<br>(http://example.org/people/bob, http://example.org/ontology/parentOf, http://example.org/people/bobby) [null]</pre>
<p>The fact that two fatherOf triples exist means that two correponding parentOf triples must be valid.&nbsp; There they are.</p>
<p>Before setting up the next example, we should clean up:</p>
<pre class="input">        conn.remove(fatherOf, RDFS.SUBPROPERTYOF, parentOf);</pre>
<h3>Domain and Range</h3>
<p>When you declare the domain and range of a predicate, the AllegroGraph inference engine can infer the rdf:type of resources found in the subject and object positions of the triple.&nbsp; For instance, in the triple &lt;<em>subject</em>, fatherOf, <em>object</em>&gt; we know that the <em>subject</em> is always an instance of class Parent, and the <em>object</em> is always an instance of class Child.&nbsp;</p>
<p>In RDF-speak, we would say that the <strong>domain</strong> of the fatherOf predicate is rdf:type Parent.&nbsp; The <strong>range</strong> of fatherOf is rdf:type Child.&nbsp; </p>
<p>This lets the inference engine determine the rdf:type of every resource that participates in a fatherOf relationship.&nbsp; </p>
<p>We'll need two new classes, Parent and Child.&nbsp; Note that RDF classes are always capitalized, just as predicates are always lowercase.</p>
<pre class="input">        URI parent = f.createURI("http://example.org/ontology/Parent");<br>        URI child = f.createURI("http://exmaple.org/ontology/Child");</pre>
<p>Now we add two triples defining the domain and rage of the fatherOf predicate: </p><pre class="input">        conn.add(fatherOf, RDFS.DOMAIN, parent);<br>        conn.add(fatherOf, RDFS.RANGE, child);</pre>
<p>Now we'll search for resources of rdf:type Parent.&nbsp; The inference engine supplies the appropriate triples: </p>
<pre class="input">        println("\nWho are the parents?  Inference ON.");<br>        printRows( conn.getStatements(null, RDF.TYPE, parent, true) );</pre>
<pre class="output">Who are the parents?  Inference ON.<br>(http://example.org/people/robert, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Parent) [null]<br>(http://example.org/people/bob, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://example.org/ontology/Parent) [null]</pre>
<p>Bob and Robert are parents.&nbsp; Who are the children? </p>
<pre class="input">        println("\nWho are the children?  Inference ON.");<br>        printRows( conn.getStatements(null, RDF.TYPE, child, true) );<br>        conn.close();</pre>
<pre class="output">Who are the children?  Inference ON.
(&lt;http://example.org/people/bobby&gt;, &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt;, &lt;http://exmaple.org/ontology/Child&gt;)
(&lt;http://example.org/people/roberta&gt;, &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt;, &lt;http://exmaple.org/ontology/Child&gt;)</pre>
<p>Bobby and Roberta are the children. &nbsp;  </p>

<h2 id="Geospatial Search">Geospatial Search (example20())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>

<p>
See also the geospatial interface
using <a href="../magic-properties.html#sparql-magic-geospatial">SPARQL magic
properties</a>, which provides a more modern geospatial interface,
not yet used in this tutorial.
</p>

<p>AllegroGraph provides the ability to locate resources within a geospatial coordinate system. You can set up either a flat (X,Y Cartesian) or spherical (latitude, longitude) system. The systems are two-dimensional only. (There is no Z or altitude dimension available). </p>
<p>The purpose of the geospatial representation is to efficiently find all entities that are located within a specific circular, rectangular or polygonal area. </p>
<h3>Cartesian System </h3>
<p>A Cartesian system is a flat (X,Y) plane. Locations are designated by (X,Y) pairs. At this time, AllegroGraph does not support real-world measurement units (km, miles, latitude, etc.,) in the Cartesian system. </p>
<p>The first example uses a Cartesian (X,Y) system that is 100 units square, and contains three people located at various points along the X = Y diagonal.</p>
<p><img src="gepCartesian.jpg" width="417" height="333"> </p>
<p>The example is in the function example20(). After establishing a connection, it begins by creating URIs for the three people.</p>
<pre class="input">        String exns = "http://example.org/people/";<br>        conn.setNamespace("ex", exns);<br>        URI alice = vf.createURI(exns, "alice");<br>        URI bob = vf.createURI(exns, "bob");<br>        URI carol = vf.createURI(exns, "carol");</pre>
<p>Then we have the connection object generate a rectangular coordinate system for us to use. A rectangular (Cartesian) system can be used to represent anything that can be plotted using (X,Y) coordinates, such as the location of transistors on a silicon chip. </p>
<pre class="input">        URI cartSystem = conn.registerCartesianType(10, 0, 100, 0, 100);</pre>
<p>The first parameter is called the <strong>stripWidth</strong>. The stripWidth parameter influences how the coordinate data is stored and retrieved, and impacts search performance. The task is to locate the people who are within a specific region. As a rule of thumb, set the stripWidth parameter to approximately the same value as the height (Y-axis) of your typical search region. You can be off by a factor of ten without impacting performance too badly, but if your application will search regions that are orders of magnitude different in size, you'll want to create multiple coordinate systems that are scaled for different sized search regions. In this case, our search region is about 20 units high (Y), and we have set the stripWidth parameter to 10 units. That's close enough.</p>
<p>The remaining parameters describe the overall size of the system. The size of the coordinate system is determined by the <strong>xMin, xMax, yMin</strong> and <strong>yMax</strong> parameters. This system is 0 to 100 in the X dimension, and 0 to 100 in the Y dimension. </p>
<p>The next step is to create a "location" predicate and enter the locations of the three people. </p>
<pre class="input">        URI location = vf.createURI(exns, "location");<br>		Literal alice_loc = vf.createLiteral("+30.0+30.0", cartSystem);<br>		Literal bob_loc = vf.createLiteral("+40.0+40.0", cartSystem);<br>		Literal carol_loc = vf.createLiteral("+50.0+50.0", cartSystem);<br>		conn.add(alice, location, alice_loc);<br>		conn.add(bob, location, bob_loc);<br>		conn.add(carol, location, carol_loc);</pre>
<p>Note that the coordinate pairs need to be encapsulated in a literal value that references the appropriate coordinate system. </p>
<p>The problem is to find the people whose locations lie within this box:</p>
<p><img src="geoBox1.jpg" width="412" height="330"></p>
<p>Locating the matching entities is remarkably easy to do. The <strong>getStatementsInBox()</strong> method requires the coordinate system object and the location predicate, plus the <strong>xmin</strong>, <strong>xmax</strong>, <strong>ymin</strong> and <strong>ymax</strong> limits of the search region. The last two arguments of the method let you place a limit on the number of results (0 means no limit), and you can optionally turn on inferencing. </p>
<pre class="input">        RepositoryResult result = conn.getStatementsInBox(cartSystem, location, 20, 40, 20, 40, 0, false);<br>        printRows(result);<br>        result.close();</pre>
<p>This retrieves all the location triples whose coordinates fall within the region. Here are the resulting triples:</p>
<pre class="output">(&lt;http://example.org/people/alice&gt;, &lt;http://example.org/people/location&gt;, 
"+30.000000004656613+30.000000004656613"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/cartesian/0.0/100.0/0.0/100.0/1.0&gt;)<br>(&lt;http://example.org/people/bob&gt;, &lt;http://example.org/people/location&gt;, 
"+39.999999990686774+39.999999990686774"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/cartesian/0.0/100.0/0.0/100.0/1.0&gt;) </pre>
<p>AllegroGraph has located Alice and Bob, as expected. Note that Bob was exactly on the corner of the search area, showing that the boundaries are inclusive. </p>
<p>We can also find all objects within a circle with a known center and radius. </p>

<p><img src="geoCircle1.jpg" width="415" height="333"></p>
<p>The getStatementsInCircle() method asks for the coordinate system object, the location predicate, the X and Y location of the circle's center, and the radius. The final two arguments are the limit and the inferencing switch. </p>
<pre class="input">        RepositoryResult result2 = conn.getStatementsInCircle(cartSystem, location, 35, 35, 10, 0, false);<br>        printRows(result2);<br>        result2.close();</pre>
<p>A search within circle1 finds Alice and Bob again:</p>
<pre class="output">(&lt;http://example.org/people/alice&gt;, &lt;http://example.org/people/location&gt;, 
"+30.000000004656613+30.000000004656613"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/cartesian/0.0/100.0/0.0/100.0/1.0&gt;)<br>(&lt;http://example.org/people/bob&gt;, &lt;http://example.org/people/location&gt;, 
"+39.999999990686774+39.999999990686774"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/cartesian/0.0/100.0/0.0/100.0/1.0&gt;) </pre>
<p>AllegroGraph can also locate points that lie within an irregular polygon. First we need to define the polygon. The polygon has to be assembled as a list of vertices which is then registered with the connection object. </p>
<pre class="input"> URI polygon1 = vf.createURI("http://example.org/polygon1");
 List&lt;Literal&gt; polygon1_points = new ArrayList&lt;Literal&gt;(4);
 polygon1_points.add(vf.createLiteral("+10.0+40.0", cartSystem));
 polygon1_points.add(vf.createLiteral("+50.0+10.0", cartSystem));
 polygon1_points.add(vf.createLiteral("+35.0+40.0", cartSystem));
 polygon1_points.add(vf.createLiteral("+50.0+70.0", cartSystem));
 conn.registerPolygon(polygon1, polygon1_points); </pre>
<p><img src="geoPolygon1.jpg" width="423" height="330"></p>
<p>When we ask what people are within polygon1, AllegroGraph finds Alice.</p>
<pre class="input">        RepositoryResult result3 = conn.getStatementsInPolygon(cartSystem, location, polygon1, 0, false);<br>        printRows(result3);<br>        result3.close();</pre>
<pre class="output">(&lt;http://example.org/people/alice&gt;, &lt;http://example.org/people/location&gt;, 
"+30.000000004656613+30.000000004656613"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/cartesian/0.0/100.0/0.0/100.0/1.0&gt;)</pre>
<h3>Spherical System</h3>
<p>A spherical coordinate system projects (X,Y) locations on a spherical surface, simulating locations on the surface of the earth. AllegroGraph supports the usual units of latitude and longitude in the spherical system. The default unit of distance is the kilometer (km). (These functions presume that the sphere is the size of the planet earth. For spherical coordinate systems of other sizes, you will have to work with the Lisp radian functions that underlie this interface.)</p>
<p><img src="geoWorld.jpg" width="602" height="340"></p>
<p>To establish a global coordinate system, use the connection object's createLatLongSystem() method. </p>
<pre class="input">         URI sphericalSystemDegree = conn.registerSphericalType(5, "degree");</pre>
<p>Once again, the <strong>stripWidth</strong> parameter is an estimate of the size of a typical search area, in the longitudinal direction this time. The default unit is the "degree", but the method also accepts kilometers ("km"). For this system, we expect a typical search to cover about five degrees in the east-west direction. Actual search regions may be as much as ten times larger or smaller without significantly impacting performance. If the application will use search regions that are significantly larger or smaller, then you will want to create multiple coordinate systems that have been optimized for different scales. </p>
<p>First we set up the resources for the entities within the spherical system. We'll need these subject URIs:</p>
<pre class="input">        URI amsterdam = vf.createURI(exns, "amsterdam");<br>        URI london = vf.createURI(exns, "london");<br>        URI sanfrancisco = vf.createURI(exns, "sanfrancisco");<br>        URI salvador = vf.createURI(exns, "salvador");</pre>
<p>Then we'll need a <strong>geolocation</strong> predicate to describe the lat/long coordinates of each entity.</p>
<pre class="input">        location = vf.createURI(exns, "geolocation");</pre>
<p>Now we can create the entities by asserting a geolocation for each one. Note that the coordinates have to be encapsulated in literal objects: </p>
<pre class="input">        conn.add(amsterdam, location, vf.createLiteral("+52.366665+004.883333",sphericalSystemDegree));<br>        conn.add(london, location, vf.createLiteral("+51.533333-000.08333333",sphericalSystemDegree));<br>        conn.add(sanfrancisco, location, vf.createLiteral("+37.783333-122.433334",sphericalSystemDegree));<br>        conn.add(salvador, location, vf.createLiteral("+13.783333-088.45",sphericalSystemDegree));</pre>
<p>The coordinates are decimal degrees. Northern latitudes and eastern longitudes are positive. </p>
<p>The next experiment is to search a box-shaped region on the surface of the sphere. (The "box" follows lines of latitude and longitude.) This region corresponds roughly to the contiguous United States. </p>
<p><img src="geoBox2.jpg" width="634" height="361"></p>
<p>Now we retrieve all the triples located within the search region:</p>
<pre class="input">        RepositoryResult result4 = conn.getStatementsInBox(sphericalSystemDegree, location, -130.0f, -70.0f, 25.0f, 50.0f, 0, false);<br>		printRows(result4);<br>		result4.close();</pre>
<p>AllegroGraph has located San Francisco:</p>
<pre class="output">(&lt;http://example.org/people/sanfrancisco&gt;, &lt;http://example.org/people/geolocation&gt;,
"+374659.49909-1222600.00212"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/
spherical/degrees/-180.0/180.0/-90.0/90.0/5.0&gt;) 
</pre>
<p>This time let's search for entities within 2000 kilometers of Mexico City, which is located at 19.3994 degrees north latitude, -99.08 degrees west longitude. </p>

<p><img src="geoCircle2.jpg" width="630" height="365"></p>
<pre class="input">		RepositoryResult result5 = conn.getGeoHaversine(sphericalSystemDegree, location, 19.3994f, -99.08f, 2000.0f, "km", 0, false);<br>		printRows(result5);<br>		result5.close();</pre>
<pre class="output">(&lt;http://example.org/people/salvador&gt;, &lt;http://example.org/people/geolocation&gt;, 
"+134659.49939-0882700"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/spherical/degrees/-180.0/180.0/-90.0/90.0/5.0&gt;)</pre>
<p>And AllegroGraph returns the triple representing El Salvador. </p>
<p>In the next example, the search area is a triangle roughly enclosing the United Kingdom. We begin by registering the polygon: </p>
<pre class="input">        URI polygon2 = vf.createURI("http://example.org/polygon2");<br>        List&lt;Literal&gt; polygon2_points = new ArrayList&lt;Literal&gt;(3);<br>        polygon2_points.add(vf.createLiteral("+51.0+002.0", sphericalSystemDegree));<br>        polygon2_points.add(vf.createLiteral("+60.0-005.0", sphericalSystemDegree));<br>        polygon2_points.add(vf.createLiteral("+48.0-012.5", sphericalSystemDegree));<br>        conn.registerPolygon(polygon2, polygon2_points);</pre>
<p><em><img src="geoPolygon2.jpg" width="631" height="385"> </em></p>
<p>We ask AllegroGraph to find all entities within this triangle:</p>
<pre class="input">        RepositoryResult result6 = conn.getStatementsInPolygon(sphericalSystemDegree, location, polygon2, 0, false);<br>        printRows(result6);<br>        result6.close();</pre>
<pre class="output">(&lt;http://example.org/people/london&gt;, &lt;http://example.org/people/geolocation&gt;, 
"+513159.49909-0000459.99970"^^&lt;http://franz.com/ns/allegrograph/3.0/geospatial/spherical/degrees/-180.0/180.0/-90.0/90.0/5.0&gt;)</pre>
<p>AllegroGraph returns the location of London, but not the nearby Amsterdam.</p>


<h2 id="Social Network Analysis">Social Network Analysis  (example21())&nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>

<p>
See also the SNA interface
using <a href="../magic-properties.html#sparql-magic-sna">SPARQL magic
properties</a>, which provides a more modern SNA interface,
not yet used in this tutorial.
</p>

<p>AllegroGraph includes sophisticated algorithms for social-network analysis (SNA). It can examine an RDF graph of relationships among people (or similar entities, such as businesses) and discover:</p>
<ul>
  <li>Cliques of mutually-supporting individuals.</li>
  <li>The importance of a person within a clique. </li>
  <li>Paths from one individual to another.</li>
  <li>Bottlenecks where information flow might be controlled or break down. </li>
</ul>
<p>This section has multiple subsections:</p>
<ul>
  <li><a href="#Example Network">Example Network</a></li>
  <li><a href="#Setting Up the Example">Setting Up the Example</a></li>
  <li><a href="#Creating SNA Generators">Creating SNA Generators</a></li>
    <li><a href="#Creating Neighbor Matrices">Creating Neighbor Matrices</a></li>
    <li><a href="#Deleting Generators and Matrices">Deleting Generators and Matrices</a></li>
    <li><a href="#SNA Search - Ego Group">SNA Search - Ego Group</a></li>
    <li><a href="#SNA Search - Path from A to B">SNA Search - Path from A to B</a></li>
    <li><a href="#Graph Measures">Graph Measures</a></li>
<!--    <li><a href="#Cliques">Cliques</a></li>
-->    <li><a href="#Actor Centrality">Actor Centrality</a></li> 
    <li><a href="#Group Centrality">Group Centrality</a></li> 
</ul>
<p>Most (but not all) of AllegroGraph's SNA features can be accessed from Java. We access them in multiple ways:</p>
<ul>
  <li>The Java Sesame API to AllegroGraph contains setup functions that let you create an SNA environment ready for queries.</li>
  <li>From Java, we can issue Prolog queries to AllegroGraph. Some of the SNA functions have Prolog equivalents that can be called directly from a query. These are explored in the sections below. </li>
  <li>Within a Prolog query, we can open a window into Lisp and reach for the AllegroGraph's Lisp SNA functions. </li>
</ul>
<h3 id="Example Network">Example Network</h3>
<p>The example file for this exercise is <strong>lesmis.rdf</strong>. It contains resources representing 80 characters from Victor Hugo's <em>Les Miserables</em>, a novel about Jean Valjean's search for redemption in 17th-century Paris. </p>
<p>The raw data behind the model measured the strength of relationships by counting the number of book chapters where two characters were both present. The five-volume novel has 365 chapters, so it was possible to create a relationship network that had some interesting features. This is a partial display of the graph in <a href="http://www.franz.com/agraph/gruff/index.lhtml">Franz's Gruff graphical browser</a>. </p>
<p><img src="lesmismap.jpg" width="768" height="426"> </p>
<p>There are four possible relationships between any two characters. </p>
<ul>
  <li><strong>No direct connection</strong>. (They never appeared in the same chapter.) AllegroGraph can locate indirect connections through their mutual acquaintances.</li>
  <li><strong>Barely knows.</strong> The characters barely know each other.</li>
  <li><span class="style2"><strong>Knows</strong></span><strong>.</strong> The two characters appear together in 15 or more chapters.</li>
  <li><span class="style3"><strong>Knows well</strong></span><strong>.</strong> The two characters appear together in 25 or more chapters. </li>
</ul>
<p>(The Gruff illustrations were made from a parallel repository in which the resources were altered to display the character's name in the graph node rather than his URI. That file is called<strong> lemisNames.rdf</strong>.) </p>
<h3 id="Setting Up the Example">Setting Up the Example</h3>
<p>The SNA examples are in function <strong>example21() </strong>in TutorialExamples.java. These are the same initializing steps we have used in previous examples. </p>
<pre class="input">    	AGServer server = new AGServer(SERVER_URL, USERNAME, PASSWORD);<br>    	AGCatalog catalog = server.getCatalog(CATALOG_ID);<br>    	catalog.deleteRepository(REPOSITORY_ID);<br>    	AGRepository myRepository = catalog.createRepository(REPOSITORY_ID);<br>    	myRepository.initialize();<br>    	AGValueFactory vf = myRepository.getValueFactory();<br>    	AGRepositoryConnection conn = myRepository.getConnection();<br>    	closeBeforeExit(conn);</pre>
<p>The next step is to load the lesmis.rdf file.</p>
<pre class="input">    	conn.add(new File(DATA_DIR, "lesmis.rdf"), null, RDFFormat.RDFXML);</pre>

<p>There are three predicates of interest in the Les Miserables repository. We need to create their URIs and bind them for later use. These are the <strong>knows, barely_knows,</strong> and <strong>knows_well</strong> predicates. </p>
<pre class="input">        // Create URIs for relationship predicates.<br>    	String lmns = "http://www.franz.com/lesmis#";<br>        conn.setNamespace("lm", lmns);<br>        URI knows = vf.createURI(lmns, "knows");<br>        URI barelyKnows = vf.createURI(lmns, "barely_knows");<br>        URI knowsWell = vf.createURI(lmns, "knows_well");</pre>
<p>We need to bind a URI Valjean as a convenience. </p>
<pre class="input">        URI valjean = vf.createURI(lmns, "character11");</pre>
<h3 id="Creating SNA Generators">Creating SNA Generators</h3>
<p>The SNA functions use "generators" to describe the relationships  we want to analyze. A generator encapsulates a list of predicates to use in social network analysis. It also describes the directions in which each predicate is interesting. </p>
<p>In an RDF graph, two resources are linked by a single triple, sometimes called a "resource-valued predicate." This triple has a resource URI in the <em>subject</em> position, and a different one in the <em>object</em> position. For instance:</p>
<pre>    (&lt;Cosette&gt;, knows_well, &lt;Valjean&gt;)</pre>
<p>This triple  is a one-way link unless we tell the generator to treat it as bidirectional. This is frequently necessary in RDF data, where inverse relations are often implied but not explicitly declared as triples. </p>
<p>For this exercise, we will declare three generators:</p>
<ul>
  <li>"intimates" uses <strong>knows_well</strong> as a bidirectional predicate.</li>
  <li>"associates" uses <strong>knows</strong> and <strong>knows_well</strong> as bidirectional predicates.</li>
  <li>"everyone" uses <strong>barely_knows</strong>, <strong>knows</strong>, and <strong>knows_well</strong> as bidirectional predicates. </li>
</ul>
<p>"Intimates" takes a narrow view of persons who know one another quite well. "Associates" follows both strong and medium relationships. "Everyone" follows all relationships, even the weak ones. This provides three levels of resolution for our analysis.</p>
<p>The connection object's <strong>registerSNAGenerator()</strong> method asks for a generator name (any label), and then for one or more predicates of interest. The predicates are bundled into lists, and then appropriate lists are assigned to the "subjectOf" direction, the "objectOf" direction, or the "undirected" direction (both ways at once). In addition, you may specify a "generator query," which is a Prolog "select" query that lets you be more specific about the links you want to analyze. </p>
<p>"Intimates" follows "knows_well" links only, and it treats them as bidirectional. If Cosette knows Valjean, then we'll assume that Valjean knows Cosette. </p>
<pre class=input>        List&lt;URI&gt; intimates = new ArrayList&lt;URI&gt;(1);<br>        Collections.addAll(intimates, knowsWell);<br>        conn.registerSNAGenerator("intimates", null, null, intimates, null);</pre>
<p>"Associates" follows "knows" and "knows_well" links. </p>
<pre class="input">        List&lt;URI&gt; associates = new ArrayList&lt;URI&gt;(2);<br>        Collections.addAll(associates, knowsWell, knows);<br>        conn.registerSNAGenerator("associates", null, null, associates, null);</pre>
<p>"Everyone" follows all three relationship links. </p>
<pre class="input">        List&lt;URI&gt; everyone = new ArrayList&lt;URI&gt;(3);<br>        Collections.addAll(everyone, knowsWell, knows, barelyKnows);<br>        conn.registerSNAGenerator("everyone", null, null, everyone, null);</pre>
<p>In these examples of registerSNAGenerator(), the five arguments represnet the name of the generator, the predicates to follow in the "object" direction, the predicates to follow in the "subject" direction, the predicates to follow in both directions, and finally, an optional Prolog query to further refine the links that are cataloged by the generator. </p>		

<h3 id="Creating Neighbor Matrices">Creating Neighbor Matrices</h3>
<p>A generator provides a powerful and flexible tool for examining a graph, but it performs repeated queries against the repository in order to extract the subgraph appropriate to your query. If your data is static, the generator will extract the same subgraph each time you use it. It is better to run the generator once and store the results for quick retrieval. </p>
<p>That is the purpose of  a "neighbor matrix." This is a persistent, in-memory cache of a generator's output. You can substitute the matrix for the generator in AllegroGraph's SNA functions. </p>
<p>The advantage of using a matrix instead of a generator is a many-fold increase in speed. This benefit is especially visible if you are searching for paths between two nodes in your graph. The exact difference in speed is difficult to estimate because there can be complex trade-offs and scaling issues to consider, but it is easy to try the experiment and observe the effect. </p>
<p>To create a matrix, use the connection object's <strong>registerNeighborMatrix()</strong> method. You must supply a matrix name (any symbol), the name of the generator, the URI of a resource to serve as the starting point, and a maximum depth. The idea is to place limits on the subgraph so that the search algorithms can operate in a restricted space rather than forcing them to analyze the entire repository. </p>
<p>In the following excerpt, we are creating three matrices to match the three generators we created. In this example, "matrix1" is the matrix for generator "intimates," and so forth. </p>
<pre class="input">        List&lt;URI&gt; startNodes = new ArrayList&lt;URI&gt;(1);<br>        startNodes.add(valjean);<br>        conn.registerSNANeighborMatrix("matrix1", "intimates", startNodes, 2);<br>        conn.registerSNANeighborMatrix("matrix2", "associates", startNodes, 5);<br>        conn.registerSNANeighborMatrix("matrix3", "everyone", startNodes, 2);</pre>
<p>A matrix is a static snapshot of the output of a generator.  If your data is dynamic, you should regenerate the matrix at intervals.</p>

<h3 id="Deleting Generators and Matrices">Deleting Generators and Matrices</h3>
<p>There is no direct way to delete individual matrices and generators, but closing the connection frees all of the resources formerly used by all of the objects and structures that were created there. </p>

<h3 id="SNA Search - Ego Group"><strong>SNA Search - Ego Group</strong></h3>
<p>Our first search will enumerate Valjean's "ego group members." This is the set of nodes (characters) that can be found by following the interesting predicates out from Valjean's node of the graph to some specified depth. We'll use the "associates" generator ("knows" and "knows_well") to specify the predicates, and we'll impose a depth limit of one link. This is the group we expect to find:</p>
<p><img src="snaEgoGroup.jpg" width="599" height="203"></p>
<p>The following Java code sends a Prolog query to AllegroGraph and returns the result to Java. </p>
<pre class="input">        println("\nValjean's ego group members (using associates).");<br>        String queryString = "(select (?member ?name)" +<br>          "(ego-group-member !lm:character11 1 associates ?member)" +<br>          "(q ?member !dc:title ?name))";<br>        TupleQuery tupleQuery = conn.prepareTupleQuery(AGQueryLanguage.PROLOG, queryString);<br>        TupleQueryResult result = tupleQuery.evaluate();<br>        int count = 0;<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            Value p = bindingSet.getValue("member");<br>            Value n = bindingSet.getValue("name");<br>            println("Member: " + p + ", name: " + n);<br>            count++;<br>        }<br>        println("Number of results: " + count);<br>        result.close();</pre>
<p>This is the iconic block of code that is repeated in all of the SNA examples, below, with minor variations in the display of bindingSet values. To save virtual trees, we'll focus more tightly on the Prolog query from this point on:</p>
<pre class="input">    (select (?member ?name)
      (ego-group-member !lm:character11 1 associates ?member)
      (q ?member !dc:title ?name))
</pre>
<p>In this example, <strong>ego-group-member</strong> is an AllegroGraph SNA function that has been adapted for use in Prolog queries. There is a list of such functions on the <a href="http://www.franz.com/agraph/support/documentation/current/lisp-reference.html#sna">AllegroGraph documentation reference page</a>. </p>
<p>The query will execute <strong>ego-group-member</strong>, using Valjean (character11) as the starting point, following the predicates described in "associates," to a depth of 1 link. It binds each matching node to <strong>?member</strong>. Then, for each binding of ?member, the query looks for the member's <strong>dc:title</strong> triple, and binds the member's <strong>?name</strong>.  The query returns multiple results, where each result is a (?member ?name) pair. The result object is passed back to Java, where we can iterate over the results and print out their values. </p>
<p>This is the output of the example:</p>
<pre class="output">Valjean's ego group members (using associates).<br>Member: http://www.franz.com/lesmis#character27, name: "Javert"<br>Member: http://www.franz.com/lesmis#character25, name: "Thenardier"<br>Member: http://www.franz.com/lesmis#character28, name: "Fauchelevent"<br>Member: http://www.franz.com/lesmis#character23, name: "Fantine"<br>Member: http://www.franz.com/lesmis#character26, name: "Cosette"<br>Member: http://www.franz.com/lesmis#character55, name: "Marius"<br>Member: http://www.franz.com/lesmis#character11, name: "Valjean"<br>Member: http://www.franz.com/lesmis#character24, name: "MmeThenardier"<br>Number of results: 8</pre>
<p>If you compare this list with the Gruff-generated image of Valjean's ego group, you'll see that AllegroGraph has found all eight expected nodes. You might be surprised that Valjean is regarded as a member of his <em>own</em> ego group, but that is a logical result of the definition of "ego group." The ego group is the set of all nodes within a certain depth of the starting point, and certainly the starting point must be is a member of that set. </p>
<p>We can perform the same search using a neighbor matrix, simply by substituting "matrix2" for "associates" in the query:</p>
<pre class="input">    (select (?member ?name)
      (ego-group-member !lm:character11 1 <strong>matrix2</strong> ?member)
      (q ?member !dc:title ?name))
</pre>
<p>This produces the same set of result nodes, but under the right circumstances the matrix would run a lot faster than the generator. </p>
<p>This variation returns Valjean's ego group as a single list. We use the member functor to pluck the individual nodes from the list: </p>
<pre class="input">    (select (?member)<br>          (ego-group !lm:character11 1 associates ?group)<br>          (member ?member ?group))</pre>
This is the output:
<pre class="output">Valjean's ego group in one list depth 1 (using associates).<br>Group: http://www.franz.com/lesmis#character27<br>Group: http://www.franz.com/lesmis#character25<br>Group: http://www.franz.com/lesmis#character28<br>Group: http://www.franz.com/lesmis#character23<br>Group: http://www.franz.com/lesmis#character26<br>Group: http://www.franz.com/lesmis#character55<br>Group: http://www.franz.com/lesmis#character11<br>Group: http://www.franz.com/lesmis#character24<br>Number of results: 8</pre>
<h3 id="SNA Search - Path from A to B">SNA Search - Path from A to B</h3>
<p>In the following examples, we explore the graph for the shortest path from Valjean to Bossuet, using the three generators to place restrictions on the quality of the path. These are the relevant paths between these two characters:</p>
<img src="pathsValBos.jpg" width="913" height="254"> 
<p>Our first query asks AllegroGraph to use <strong>intimates</strong> to find the shortest possible path between Valjean and Bossuet that is composed entirely of "knows_well" links. Those would be the green arrows in the diagram above. The <strong>breadth-first-search-path</strong> function asks for a start node and an end node, a generator, an optional maximum path length, and a variable to bind to the resulting path. Valjean is character11, and Bossuet is character64.</p>
<pre class="input">(select (?node)<br>          (breadth-first-search-path !lm:character11 !lm:character64 intimates 5 ?path)<br>          (member ?node ?path))</pre>
<p>It is easy to examine the diagram and see that there is no such path. Valjean and Bossuet are not well-acquainted, and do not have any chain of well-acquainted mutual friends. AllegroGraph lets us know that.</p>
<pre class="output">Shortest breadth-first path connecting Valjean to Bossuet using intimates. (Should be no path.)<br>Number of results: 0</pre>
<p>This time we'll broaden the criteria. What is the shortest path from Valjean to Bossuet, using <strong>associates</strong>? We can follow either "knows_well" or "knows" links across the graph. Those are the green and the blue links in the diagram. </p>
<pre class="input">(select (?node)<br>          (breadth-first-search-path !lm:character11 !lm:character64 associates 5 ?path)<br>          (member ?node ?path))</pre>
<p>This function returns the first successful path, which is guaranteed to be a shortest path. </p>
<pre class="output">Shortest breadth-first path connecting Valjean to Bossuet using associates. <br>Node on path: http://www.franz.com/lesmis#character11<br>Node on path: http://www.franz.com/lesmis#character55<br>Node on path: http://www.franz.com/lesmis#character62<br>Node on path: http://www.franz.com/lesmis#character64<br>Number of results: 4</pre>
<p>These is the path "Valjean &gt; Marius &gt; Enjolras &gt; Bossuet." </p>
<p>Our third query asks for the shortest path from Valjean to Bossuet using <strong>everyone</strong>, which means that "barely-knows" links are permitted in addition to "knows" and "knows_well" links. </p>
<pre class="input">(select (?node)<br>          (breadth-first-search-path !lm:character11 !lm:character64 everyone 5 ?path)<br>          (member ?node ?path))</pre>
<p>This time AllegroGraph returns a two-step path:</p>
<pre class="output">Shortest breadth-first path connecting Valjean to Bossuet using everyone.<br>Node on Path: http://www.franz.com/lesmis#character11<br>Node on Path: http://www.franz.com/lesmis#character64<br>Number of results: 2</pre>
<p>This is the "barely-knows" link directly from from Valjean to Bossuet. </p>
<p>The Prolog select query can also use <strong>depth-first-search-path()</strong> and <strong>bidirectional-search-path()</strong>. Their syntax is essentially identical to that shown above. These algorithms offer different efficiencies:</p>
<ul>
  <li>Breadth-first and bidirectional searches explore all paths by incrementing the search radius until a success is achieved. This guarantees that the returned path(s) will be "shortest" paths. They return one or more paths of equal length. </li>
  <li>Depth-first search tries to bypass the costly expansion of all paths by exploring each path to its end, and aborting the search when it locates a successful path. There is no implication that this path is the "shortest" path through the graph. </li>
</ul>
<p>In addition, the depth-first algorithm uses less memory than the others, so a depth-first search may succeed when a breadth-first search would run out of memory. </p>
<h3 id="Graph Measures">Graph Measures</h3>
<p>AllegroGraph provides several utility functions that measure the characteristics of a node, such as the number of connections it has to other nodes, and its importance as a communication path in a clique. </p>
<p>For instance, we can use the <strong>nodal-degree</strong> function to ask how many nodal neighbors Valjean has, using <strong>everyone</strong> to catalog all the nodes connected to Valjean by "knows," "barely_knows", and "knows_well" predicates. There are quite a few of them:</p>
<p><img src="allLinksValjean.jpg" width="720" height="341"> </p>
<p>The nodal-degree function requires the URI of the target node (Valjean is character11), the generator, and a variable to bind the returned value to. </p>
<pre class="input">        println("\nHow many neighbors are around Valjean? (should be 36).");<br>        queryString = "(select (?neighbors)" +<br>          "(nodal-degree !lm:character11 everyone ?neighbors))";<br>        tupleQuery = conn.prepareTupleQuery(AGQueryLanguage.PROLOG, queryString);<br>        result = tupleQuery.evaluate();<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            Value p = bindingSet.getValue("neighbors");<br>            println("Neighbors: " + p );<br>            println("Neighbors: " + p.stringValue());<br>        }<br>        result.close();</pre>

<p>Note that this function returns a string that describes an integer, which in its raw form is difficult for Java to use. We convert the raw value to a Java integer using the <strong>.stringValue() </strong>method that is available to all literal values in the Java Sesame API to AllegroGraph. This example prints out both the string value and the converted number.</p>
<pre class="output">How many neighbors are around Valjean? (should be 36).
"36"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt;
36</pre>
<p>If you want to see the names of these neighbors, you can use either the <strong>ego-group-member</strong> function described earlier on this page, or the <strong>nodal-neighbors</strong> function shown below:</p>
<pre class="input">        println("\nWho are Valjean's neighbors? (using everyone).");<br>        queryString = "(select (?name)" +<br>          "(nodal-neighbors !lm:character11 everyone ?member)" +<br>          "(q ?member !dc:title ?name))";<br>        tupleQuery = conn.prepareTupleQuery(AGQueryLanguage.PROLOG, queryString);<br>        result = tupleQuery.evaluate();<br>        count = 0;<br>        while (result.hasNext()) {<br>            BindingSet bindingSet = result.next();<br>            Value p = bindingSet.getValue("name");<br>            count++;<br>            println(count + ". " + p.stringValue());<br>        }<br>        result.close();</pre>
<p>This example enumerates all immediate neighbors of Valjean and returns their names in a numbered list. There are 36 names in the full list. <pre class="output">Who are Valjean's neighbors? (using everyone).<br>1. Isabeau<br>2. Fantine<br>3. Labarre<br>4. Bossuet<br>5. Brevet ...</pre>

<p>Another descriptive statistic is <strong>graph-density</strong>, which measures the density of connections within a subgraph. </p>
<p>For instance, this is Valjean's ego group with all <strong>associates</strong>  included. </p>
<p><img src="graphDensity.jpg" width="806" height="297"> </p>
<p>Only 9 of 28 possible links are in place in this subgraph, so the graph density is 0.32. The following query asks AllegroGraph to calculate this figure for Valjean's ego group:</p>
<pre class="input">
    (select (?density)
      (ego-group !lm:character11 1 associates ?group)
      (graph-density ?group associates ?density))
</pre>
<p>We used the<strong> ego-group</strong> function to return a list of Valjean's ego-group members, bound to the variable <strong>?group</strong>, and then we used ?group to feed that subgraph to the <strong>graph-density</strong> function. The return value, <strong>?density</strong>, came back as a string describing a float, and had to be converted to a Java float using <strong>.toJava()</strong>.</p>
<pre class="output">Graph density of Valjean's ego group? (using associates).<br>Graph density: 3.2142857e-1</pre>
<!-- Commented out until the clique function is more graceful in Java. BDC
<h3 id="Cliques">Cliques</h3>
<p>A "clique" is a subgraph where every node is connected to every other node by predicates specified in some generator. AllegroGraph, using everyone ("knows," "knows_well," and "barely_knows"), found that Valjean participates in 239 cliques! </p>
<p><img src="valjeanBigClique.jpg" width="859" height="301"> </p>
<p>It is counterintuitive that a "clique" should be composed mainly of people who "barely_know" each other, so let's try the same experiment using "associates," which restricts the cliques to people Valjean "knows" or "knows_well." In this case, AllegroGraph returns two cliques. One contains Valjean, Cosette, and Marius. The other contains Valjean and the Thenardiers. </p>
<p><img src="valjeanSmallCliques.jpg" width="397" height="248"> </p>
<p>This is the query that finds Valjean's "associates" cliques:</p>
<pre class="input">select (?member)<br>          (clique !lm:character11 associates ?clique)<br>          (member ?member ?clique))</pre>



<p>AllegroGraph returns two cliques:</p>
<pre class="output">Valjean's cliques? Should be two (using associates).<br>Clique: "({character11} {character25} {character24})"<br>Clique: "({character11} {character55} {character26})"<br>Number of results: 2</pre>
<p>The first list is the clique with Marius and Cosette. The second one represents the Thernardier clique. </p>
-->
<h3 id="Actor Centrality">Actor Centrality </h3>
<p>AllegroGraph lets us measure the relative importance of a node in a subgraph using the <strong>actor-degree-centrality()</strong> function. For instance, it should be obvious that Valjean is very "central" to his own ego group (depth of one link), because he is linked directly to all other links in the subgraph. In that case he is linked to 7 of 7 possible nodes, and his actor-degree-centrality value is 7/7 = 1. </p>
<p>However, we can regenerate Valjean's ego group using a depth of 2. This adds three nodes that are not directly connected to Valjean. How "central" is he then?</p>
<p><img src="valjeanActorCentrality.jpg" width="875" height="303"> </p>
<p>In this subgraph, Valjean's actor-degree-centrality is 0.70, meaning that he is connected to 70% of the nodes in the subgraph. </p>
<p>This example asks AllegroGraph to generate the expanded ego group, and then to measure Valjean's actor-degree-centrality:</p>
<pre class="input">
    (select (?centrality)
      (ego-group !lm:character11 2 associates ?group)
      (actor-degree-centrality !lm:character11 ?group associates ?centrality))
</pre>
<p>Note that we asked <strong>ego-group()</strong> to explore to a depth of two links, and then fed its result (<strong>?group</strong>) to <strong>actor-degree-centrality()</strong>. This is the output:</p>
<pre class="output">Valjean's actor-degree-centrality to his ego group at depth 2 (using associates).<br>Centrality: 7.0e-1</pre>
<p>This confirms our expectation that Valjean's actor-degree-centrality should be 0.70 in this circumstance.</p>
<p>We can also measure actor centrality by calculating the average path length from a given node to the other nodes of the subgraph. This is called <strong>actor-closeness-centrality</strong>. For instance, we can calculate the average path length from Valjean to the ten nodes of his ego group (using associates and depth 2). Then we take the inverse of the average, so that bigger values will be "more central." </p>
<p><img src="valjeanActorClosenessCentrality.jpg" width="875" height="303"> </p>
<p>The actor-closeness-centrality for Marius is 0.60, showing that Valjean is more central and important to the group than is Marius. </p>
<p>This example calculates Valjean's <strong>actor-closeness-centrality</strong> for the associates ego group of depth 2. </p>
<pre class="input">
    (select (?centrality)
      (ego-group !lm:character11 2 associates ?group)
      (actor-closeness-centrality !lm:character11 ?group associates ?centrality))
</pre>
<pre class="output">Valjean's actor-closeness-centrality to his ego group at depth 2 (using associates).<br>Centrality: 7.692308e-1</pre>
<p>That is the expected value of 0.769. </p>
<p>Another approach to centrality is to count the number of information paths that are "controlled" by a specific node. This is called<strong> actor-betweenness-centrality</strong>. For instance, there are 45 possible "shortest paths" between pairs of nodes in Valjean's associates depth-2 ego group. Valjean can act as an information valve, potentially cutting off communication on 34 of these 45 paths. Therefore, he controls 75% of the communication in the group. </p>
<p><img src="valjeanActorBetweenCentrality.jpg" width="875" height="303"></p>
<p>This example calculates Valjean's actor-betweenness-centrality:</p>
<pre class="input">
    (select (?centrality)
      (ego-group !lm:character11 2 associates ?group)
      (actor-betweenness-centrality !lm:character11 ?group associates ?centrality))
</pre>

<pre class="output">Valjean's actor-betweenness-centrality to his ego group at depth 2 (using associates).<br>Centrality: 7.5555557e-1</pre>
<p>That's the expected result of 0.755. </p>
<h3 id="Group Centrality">Group Centrality</h3>
<p>Group-centrality measures express the "cohesiveness" of a group. There are three group-centrality measures in AllegroGraph: <strong>group-degree-centrality()</strong>, <strong>group-closeness-centrality()</strong>, and <strong>group-betweenness-centrality()</strong>.</p>
<p>To demonstrate these measures, we'll use Valjean's ego group, first at radius 1 and then at radius 2. As you recall, the smaller ego group is radially symmetrical, but the larger one is quite lop-sided. That makes the smaller group "more cohesive" than the larger one.</p>
<p> <strong>Group-degree-centrality()</strong> measures group cohesion by finding the maximum actor centrality in the group, summing the difference between this and each other actor's degree centrality, and then normalizing. It ranges from 0 (when all actors have equal degree) to 1 (when one actor is connected to every other and no other actors have connections.</p>
<p>The prolog query takes this form:</p>
<pre class="input"> (select (?centrality)
   (ego-group !lm:character11 1 associates ?group)
   (group-degree-centrality ?group associates ?centrality))</pre>
<p>The query first generates Valjean's (character11) ego group at radius 1, and binds that list of characters to ?group. Then it calls group-degree-centrality() on the group and returns the answer as ?centrality. </p>
<p>The group-degree-centrality for Valjean's radius-1 ego group is 0.129. When we expand to radius 2, the group-degree-centrality drops to 0.056. The larger group is less cohesive than the smaller one. </p>
<p>The following examples were all generated from queries that strongly resemble the one above. </p>
<p> <strong>Group-closeness-centrality()</strong> is measured by first finding the actor whose `closeness-centrality` <br>
  is maximized and then summing the difference between this maximum value and the actor-closeness-centrality of all other actors. This value is then normalized so that it ranges between 0 and 1. </p>
<p>The group-closeness-centrality of Valjean's smaller ego group is 0.073. The expanded ego group has a group-closeness-centrality of 0.032. Again, the larger group is less cohesive.</p>
<p> Group-betweenness-centrality() is measured by first finding the actor whose actor-betweenness-centrality<br>
  is maximized and then summing the difference between this maximum value and the actor-betweenness-centrality of all other actors. This value is then normalized so that it ranges between 0 and 1. </p>
<p>Valjean's smaller ego group has a group-betweenness-centrality of 0.904. The value for the larger ego group is 0.704. Even by this measure, the larger group is less cohesive. </p>
<h2 id="Transaction">Transaction (example22())</h2>
<p>Triples are normally loaded one at a time in "auto-commit" mode. Each triple enters the triple store individually. It is possible that a batch of incoming triples, all describing the same resource, might be interrupted for some reason. An interrupted load can leave the triple store in an unknown state. </p>
<p>In some applications we can't run the risk of having a resource that is incomplete.  To guard against this hazard, AllegroGraph can turn off auto-commit behavior and use "transaction" behavior instead. With auto-commit turned off, we can add triples until we have a complete set, a known state. If anything goes wrong to interrupt the load, we can roll the transaction back and start over. Otherwise, commit the transaction and all the triples will enter the store at once. </p>
<p>In order to use transaction semantics, the user account must have "start sessions" privileges with AllegroGraph Server. This is an elevated level of privilege. AllegroGraph users are profiled through the <a href="#Creating Users with WebView">WebView interface.</a></p>
<p>To experiment with transaction semantics in AllegroGraph, we will need two connections to the triple store. In the "transaction connection" we will load, rollback, reload and commit incoming triples.&nbsp; In the "autocommit connection" we will run queries against the resulting triple store, where the resources are always in a known and complete state. </p>
<p>In practice, transactions require only one connection.&nbsp; We create a special connection for transaction behavior, use it, and close it. </p>
<p>"Commit" means to make a batch of newly-loaded triples visible in the auto-commit connection. The two sessions are "synched up" by the commit. Any "new" triples added to either connection will suddenly be visible in both connections after a commit. </p>
<p>"Rollback" means to discard the recent additions to the transaction connection. This, too, synchs up the two sessions. After a rollback, the transaction connection "sees" exactly the same triples as the auto-commit connection does. </p>
<p>"Closing" the transaction connection deletes all uncommitted triples, and all rules, generators and matrices that were created in that connection. Rules, generators and matrices cannot be committed. </p>
<p>Example22() performs some simple data manipulations on a transaction connection to demonstrate the rollback and commit features. It begins by creating two connections to the repository. Then we turn one of them into a "transaction" connection by setting <strong>setAutoCommit()</strong> to <strong>false</strong>. </p>
<pre class="input">    public static void example22() throws Exception {<br>        AGServer server = new AGServer(SERVER_URL, USERNAME, PASSWORD);<br>        AGCatalog catalog = server.getCatalog(CATALOG_ID);<br>        AGRepository myRepository = catalog.createRepository("agraph_test");<br>        myRepository.initialize();<br>        AGValueFactory vf = myRepository.getValueFactory();<br>        // Create conn1 (autoCommit) and conn2 (no autoCommit).<br>        AGRepositoryConnection conn1 = myRepository.getConnection();<br>        closeBeforeExit(conn1);<br>        conn1.clear();<br>        AGRepositoryConnection conn2 = myRepository.getConnection();<br>        closeBeforeExit(conn2);<br>        conn2.clear();<br>        conn2.setAutoCommit(false);</pre>
<p>In this example,<strong> conn1</strong> is the auto-commit session, and <strong>conn2</strong> will be used for transactions. </p>
<p>We'll reuse the Kennedy and Les Miserables data. The Les Miserables data goes in the auto-commit session, and the Kennedy data goes in the transaction session. </p>
<pre class="input">        String baseURI = "http://example.org/example/local";<br>        conn1.add(new File(DATA_DIR, "lesmis.rdf"), baseURI, RDFFormat.RDFXML);<br>        println("Loaded " + conn1.size() + " lesmis.rdf triples into conn1.");<br>        conn2.add(new File(DATA_DIR, "java-kennedy.ntriples"), baseURI, RDFFormat.NTRIPLES);<br>        println("Loaded " + conn2.size() + " java-kennedy.ntriples into conn2.");</pre>
<p>The two sessions should now have independent content. When we look in the auto-commit session we should see only Les Miserables triples. The transaction session could contain only Kennedy triples. We set up a series of simple tests similar to this one:</p>
<pre class="input">        Literal valjean = vf.createLiteral("Valjean");<br>        Literal kennedy = vf.createLiteral("Kennedy");<br>        printRows("\nUsing getStatements() on conn1 should find Valjean:",<br>                1, conn1.getStatements(null, null, valjean, false));</pre>
<p>This test looks for our friend Valjean in the auto-commit session. He should be there. This is the output:</p>
<pre class="output">Using getStatements() on conn1 should find Valjean:<br>(http://www.franz.com/lesmis#character11, http://purl.org/dc/elements/1.1/title, "Valjean") [null]<br>Number of results: 1</pre>
<p>However, there should not be anyone in the auto-commit session named "Kennedy." The code of the test is almost identical to that shown above, so we'll skip straight to the output.</p>
<pre class="output">Using getStatements() on conn1 should not find Kennedy:<br>Number of results: 0</pre>
<p>We should not see Valjean in the transaction session:</p>
<pre class="output">Using getStatements() on conn2 should not find Valjean:<br>Number of results: 0</pre>
<p>There should be a Kennedy (at least one) visible in the transaction session. (We limited the output to one match.) </p>
<pre class="output">Using getStatements() on conn2 should find Kennedy:<br>(http://www.franz.com/simple#person1, http://www.franz.com/simple#last-name, "Kennedy") [null]<br>Number of results: 1</pre>
<p>The next step in the demonstration is to roll back the data in the transaction session. This will make the Kennedy data disappear. It will also make the Les Miserables data visible in both sessions. We'll perform the same four tests, with slightly different expectations.</p>

<p>First we roll back the transaction:</p>
<pre class="input">        println("\nRolling back contents of conn2.");<br>        conn2.rollback();</pre>
<p>Valjean is still visible in the auto-commit session:</p>
<pre class="output">Using getStatements() on conn1 should find Valjean:<br>(http://www.franz.com/lesmis#character11, http://purl.org/dc/elements/1.1/title, "Valjean") [null]<br>Number of results: 1</pre>
<p>There are still no Kennedys in the auto-commit session: </p>
<pre class="output">Using getStatements() on conn1 should not find Kennedys:<br>Number of results: 0</pre>
<p>There should be no Kennedys visible in the transaction session:</p>
<pre class="output">Using getStatements() on conn2 should not find Kennedys:<br>Number of results: 0</pre>
<p>And finally, we should suddenly see Valjean in the transaction session:</p>
<pre class="output">Using getStatements() on conn2 should find Valjean:<br>(http://www.franz.com/lesmis#character11, http://purl.org/dc/elements/1.1/title, "Valjean") [null]<br>Number of results: 1</pre>
<p>The rollback has succeeded in deleting the uncommitted triples from the transaction session. It has also refreshed or resynched the transaction session with the auto-commit session.</p>
<p>To set up the next test, we have to reload the Kennedy triples. Then we'll perform a commit.  </p>
<pre class="input">        println("\nReload 1214 java-kennedy.ntriples into conn2.");<br>        conn2.add(new File(DATA_DIR, "java-kennedy.ntriples"), baseURI, RDFFormat.NTRIPLES);<br>        println("\nCommitting contents of conn2.");<br>        conn2.commit();</pre>
<p>This should make both types of triples visible in both sessions. Here are the four tests:</p>
<pre class="output">Using getStatements() on conn1 should find Valjean:
(http://www.franz.com/lesmis#character11, http://purl.org/dc/elements/1.1/title, "Valjean") [null]
Number of results: 1

Using getStatements() on conn1 should find Kennedys:
(http://www.franz.com/simple#person1, http://www.franz.com/simple#last-name, "Kennedy") [null]
Number of results: 1

Using getStatements() on conn2 should find Kennedys:
(http://www.franz.com/simple#person1, http://www.franz.com/simple#last-name, "Kennedy") [null]
Number of results: 1

Using getStatements() on conn2 should find Valjean:
(http://www.franz.com/lesmis#character11, http://purl.org/dc/elements/1.1/title, "Valjean") [null]
Number of results: 1</pre>
<p>The Les Miserables triples are visible in both sessions. So too are the Kennedy triples. </p>
<h2 id="Duplicate Triples">Duplicate Triples (example23()) &nbsp;&nbsp;&nbsp;<a class="returnlink" href="#Contents">Return to Top</a></h2>
<p>Most people find it annoying when a query returns multiple copies of the same information. This can happen in mulitple ways, and there are multiple strategies for reducing or eliminating the problem. There are two broad strategies to pursue:</p>
<ul>
  <li>Don't create duplicate triples. It is surprisingly easy to fill the triple store with duplicates if you are not careful to generate clean RDF files.</li>
  <li>Filter the duplicate results from the output of your queries. SPARQL in particular has features that reduce or eliminate duplicate results. </li>
</ul>
<h3>Tighten Up Your Queries</h3>
<p>Triple patterns sometimes act in unexpected ways, resulting in "too many" matches.</p>
<p><strong>Example23()</strong> revives the Kennedy family tree. It loads the <strong>java-kennedy.ntriples</strong> file, resulting in 1214 triples.</p>
<p>This example focuses on the three children of Ted Kennedy (person17). A simple <strong>getStatements() </strong>query shows us that all three are, in fact, present. They are person72, person74, and person76. </p>
<pre class="output">Using getStatements() find children of Ted Kennedy: three children.<br>(http://www.franz.com/simple#person17, http://www.franz.com/simple#has-child, http://www.franz.com/simple#person72) [null]<br>(http://www.franz.com/simple#person17, http://www.franz.com/simple#has-child, http://www.franz.com/simple#person74) [null]<br>(http://www.franz.com/simple#person17, http://www.franz.com/simple#has-child, http://www.franz.com/simple#person76) [null]<br>Number of results: 3</pre>
<p>Let's imagine that for some bureaucratic or legal reason we need to retrieve any two of the senator's three children from the triple store. We might begin with a SPARQL query like this one:</p>
<pre class="input">    SELECT ?o1 ?o2 <br>       WHERE {kdy:person17 kdy:has-child ?o1 .<br>              kdy:person17 kdy:has-child ?o2 .} </pre>
<p>Since there are only three ways to retrieve a pair from a pool of three, we might be startled to get nine answers:</p>
<pre class="output">SPARQL matches for two children of Ted Kennedy, inept pattern.<br>&lt;http://www.franz.com/simple#person72&gt; and &lt;http://www.franz.com/simple#person72&gt;<br>&lt;http://www.franz.com/simple#person72&gt; and &lt;http://www.franz.com/simple#person74&gt;<br>&lt;http://www.franz.com/simple#person72&gt; and &lt;http://www.franz.com/simple#person76&gt;<br>&lt;http://www.franz.com/simple#person74&gt; and &lt;http://www.franz.com/simple#person72&gt;<br>&lt;http://www.franz.com/simple#person74&gt; and &lt;http://www.franz.com/simple#person74&gt;<br>&lt;http://www.franz.com/simple#person74&gt; and &lt;http://www.franz.com/simple#person76&gt;<br>&lt;http://www.franz.com/simple#person76&gt; and &lt;http://www.franz.com/simple#person72&gt;<br>&lt;http://www.franz.com/simple#person76&gt; and &lt;http://www.franz.com/simple#person74&gt;<br>&lt;http://www.franz.com/simple#person76&gt; and &lt;http://www.franz.com/simple#person76&gt; </pre>
<p>Three of these matches involve the same triple matching both patterns, claiming that each person is a sibling of himself. The other six are permutations of the correct answers, in which we first discover that person72 is a sibling of person74, and then subsequently discover that person74 is a sibling of person72. We didn't need to receive that information twice. </p>
<p>Let's eliminate the useless duplications with a simple trick. Here it is in SPARQL: </p>
<pre class="input">    SELECT ?o1 ?o2 <br>       WHERE {kdy:person17 kdy:has-child ?o1 .<br>              kdy:person17 kdy:has-child ?o2 .<br>              filter (?o1 &lt; ?o2)} </pre>
<p>And this is the equivalent query in Prolog. Note that <strong>lispp</strong> is correct, not a typo:</p>
<pre class="input">    (select (?o1 ?o2)<br>            (q !kdy:person17 !kdy:has-child ?o1)<br>            (q !kdy:person17 !kdy:has-child ?o2) <br>			(lispp (upi&lt; ?o1 ?o2)))</pre>
<p>The inequality insures that the two object variables cannot be bound to the same value, eliminating the sibling-of-self issue, and also that only one of the persons can be bound to ?o1, which eliminates the duplication issue. Now we have the expected three results:</p>
<pre class="output">SPARQL matches for two children of Ted Kennedy, better pattern.<br>&lt;http://www.franz.com/simple#person72&gt; and &lt;http://www.franz.com/simple#person74&gt;<br>&lt;http://www.franz.com/simple#person72&gt; and &lt;http://www.franz.com/simple#person76&gt;<br>&lt;http://www.franz.com/simple#person74&gt; and &lt;http://www.franz.com/simple#person76&gt;
</pre>
<p>Our task, however, is to pluck "any two" of the children from the triple store and then stop. That's easy in SPARQL:</p>
<pre class="input">    SELECT ?o1 ?o2 <br>       WHERE {kdy:person17 kdy:has-child ?o1 .<br>              kdy:person17 kdy:has-child ?o2 .<br>              filter (?o1 &lt; ?o2)}<br>              LIMIT 1 </pre>
<p>This query returns one result that is guaranteed to reference two different children. </p>
<p>The moral of this example is that triple patterns often return more information than you expected, and need to be rewritten to make them less exuberant. You may be able to reduce the incidence of duplicate results simply by writing better queries. </p>
<h3>Tighten Up Your RDF</h3>
<p>The Resource Description Framework (RDF) has many fine qualities, but there are also a few RDF features that create headaches for users. One of these is the ability to encode resources as "blank nodes." This is a convenience to the person who is generating the data, but it often creates problems for the data consumer.</p>
<p>Here's a simple example. These two RDF resource descriptions represent two books by the same author. The author is described using a "blank node" within the book resource description:</p>
<pre class="input">  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book1"&gt;<br>    &lt;dc:title&gt;The Call of the Wild&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator&gt;<br>	   &lt;foaf:Person foaf:name="Jack London"/&gt; <br>    &lt;/dc:creator&gt;</strong><br>  &lt;/rdf:Description&gt;<br>  <br>  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book2"&gt;<br>    &lt;dc:title&gt;White Fang&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator&gt;<br>	   &lt;foaf:Person foaf:name="Jack London"/&gt; <br>    &lt;/dc:creator&gt;</strong><br>  &lt;/rdf:Description&gt; </pre>
<p>This is a common RDF format used by programs that transcribe databases into RDF. In this format, there is no resource URI designated for the author resource. Therefore, the RDF parser will generate a URI to use as the subject value of the new resource. The problem is that it generates a new URI each time it encounters an embedded resource. We wind up with eight triples and two different "Jack London" resources:</p>
<pre class="output">Two books, with one author as blank node in each book.<br>(http://www.franz.com/tutorial#book1, http://purl.org/dc/elements/1.1/creator, _:189) [null]<br>(http://www.franz.com/tutorial#book1, http://purl.org/dc/elements/1.1/title, "The Call of the Wild") [null]

(http://www.franz.com/tutorial#book2, http://purl.org/dc/elements/1.1/creator, _:190) [null]<br>(http://www.franz.com/tutorial#book2, http://purl.org/dc/elements/1.1/title, "White Fang") [null]<br>
(_:190, http://xmlns.com/foaf/0.1/name, "Jack London") [null]<br>(_:190, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://xmlns.com/foaf/0.1/Person) [null]<br>
(_:189, http://xmlns.com/foaf/0.1/name, "Jack London") [null]<br>(_:189, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://xmlns.com/foaf/0.1/Person) [null]<br><br>Number of results: 8</pre>
<p>You can see the two books, each with a title and a creator. Then there are two "anonymous" resources with generated subject URIs, both of which represent the same author. This is very undesirable. </p>
<p>Duplicate <em>resources</em> are difficult to remove or fix. They have different subject values, which mean their triples are technically not duplicates of each other. The author resources are directly linked to book resources, one-to-one, meaning that you can't just delete the extra authors. That would leave book resources linked to authors that don't exist anymore. </p>
<p>Clearly we don't want to be in this situation. We have to back out and generate the RDF a different way. </p>
<p>We might decide to fix this problem by rewriting the resource descriptions. This time we'll be sure that the formerly anonymous nodes are set up with URIs. This way we'll get only one author resource. This format is what RDF calls "striped syntax."</p>
<pre class="input">  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book1"&gt;<br>    &lt;dc:title&gt;The Call of the Wild&lt;/dc:title&gt;<br>    &lt;dc:creator&gt;<br>	   <strong>&lt;foaf:Person rdf:about="#Jack"&gt;<br>	      &lt;foaf:name&gt;Jack London&lt;/foaf:name&gt; <br>	   &lt;/foaf:Person&gt;</strong><br>	&lt;/dc:creator&gt;<br>  &lt;/rdf:Description&gt;<br>  <br>  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book2"&gt;<br>    &lt;dc:title&gt;White Fang&lt;/dc:title&gt;<br>    &lt;dc:creator&gt;<br>	   <strong>&lt;foaf:Person rdf:about="#Jack"&gt;<br>	      &lt;foaf:name&gt;Jack London&lt;/foaf:name&gt; <br>	   &lt;/foaf:Person&gt;</strong><br>	&lt;/dc:creator&gt;<br>  &lt;/rdf:Description&gt;</pre>
<p>Even though we have embedded two resource descriptions, we gave them both the same URI ("#Jack"). Did this solve the problem? We now have only one "Jack London" resource, but we still have eight triples! </p>
<pre class="output">Two books, with one author identified by URI but in striped syntax in each book.<br>(http://www.franz.com/tutorial#book1, http://purl.org/dc/elements/1.1/creator, http://example.org#Jack) [null]<br>(http://www.franz.com/tutorial#book1, http://purl.org/dc/elements/1.1/title, "The Call of the Wild") [null]<br>
(http://www.franz.com/tutorial#book2, http://purl.org/dc/elements/1.1/creator, http://example.org#Jack) [null]<br>(http://www.franz.com/tutorial#book2, http://purl.org/dc/elements/1.1/title, "White Fang") [null]<br>
(http://example.org#Jack, http://xmlns.com/foaf/0.1/name, "Jack London") [null]<br>(http://example.org#Jack, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://xmlns.com/foaf/0.1/Person) [null]<br>
(http://example.org#Jack, http://xmlns.com/foaf/0.1/name, "Jack London") [null]<br>(http://example.org#Jack, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://xmlns.com/foaf/0.1/Person) [null]<br>Number of results: 8</pre>
<p>We have only one "Jack London" author resource, which means we will have a more useful graph than before, but <em>every triple in that resource is duplicated</em>. If we had cataloged fifty books by Jack London, there would be fifty copies of each of these triples. The "striped syntax" generates floods of duplicate triples. </p>
<p>It is much better to avoid blank nodes and striped syntax altogether. Here are the same two books, using a separate author resource that is linked to the books by a URI:</p>
<pre class="input">  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book5"&gt;<br>    &lt;dc:title&gt;The Call of the Wild&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator rdf:resource="http://www.franz.com/tutorial#author1"/&gt;</strong><br>  &lt;/rdf:Description&gt;<br>  <br>  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book6"&gt;<br>    &lt;dc:title&gt;White Fang&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator rdf:resource="http://www.franz.com/tutorial#author1"/&gt;</strong><br>  &lt;/rdf:Description&gt;<br>  <br>  &lt;rdf:Description <strong>rdf:about="http://www.franz.com/tutorial#author1"</strong>&gt;<br>    &lt;dc:title&gt;Jack London&lt;/dc:title&gt;<br>  &lt;/rdf:Description&gt; </pre>
<p>This is arguably the "best" syntax to follow because one author resource is directly connected to all of that author's books. The graph is rich in nodes and connections, while avoiding duplicate triples. This example creates six triples, none of which are duplicates:</p>
<pre class="output">Two books, with one author linked by a URI.<br>(http://www.franz.com/tutorial#book5, http://purl.org/dc/elements/1.1/creator, http://www.franz.com/tutorial#author1) [null]<br>(http://www.franz.com/tutorial#book5, http://purl.org/dc/elements/1.1/title, "The Call of the Wild") [null]<br>
(http://www.franz.com/tutorial#book6, http://purl.org/dc/elements/1.1/creator, http://www.franz.com/tutorial#author1) [null]<br>(http://www.franz.com/tutorial#book6, http://purl.org/dc/elements/1.1/title, "White Fang") [null]<br>
(http://www.franz.com/tutorial#author1, http://purl.org/dc/elements/1.1/title, "Jack London") [null]<br>(http://www.franz.com/tutorial#author1, http://www.w3.org/1999/02/22-rdf-syntax-ns#type, http://xmlns.com/foaf/0.1/Person) [null]<br>Number of results: 6</pre>
<p>There is only one way to simplify the example from here. Perhaps you really don't need author resources at all. It could be sufficient to know the name of a book's author and never reify the author as a node in the graph. In that case, you can pare down the resource descriptions by including the author name as a literal string:</p>
<pre  class="input">  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book3"&gt;<br>    &lt;dc:title&gt;The Call of the Wild&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator&gt;Jack London&lt;/dc:creator&gt;</strong><br>  &lt;/rdf:Description&gt;<br>  <br>  &lt;rdf:Description rdf:about="http://www.franz.com/tutorial#book4"&gt;<br>    &lt;dc:title&gt;White Fang&lt;/dc:title&gt;<br>    <strong>&lt;dc:creator&gt;Jack London&lt;/dc:creator&gt;</strong><br>  &lt;/rdf:Description&gt;   
</pre>
<p>This example generates only four triples, none of which are duplicates. We have two books, and no author resource. </p>
<pre class="output" >Two books, with one author as a literal value.<br>(http://www.franz.com/tutorial#book3, http://purl.org/dc/elements/1.1/creator, "Jack London") [null]<br>(http://www.franz.com/tutorial#book3, http://purl.org/dc/elements/1.1/title, "The Call of the Wild") [null]

(http://www.franz.com/tutorial#book4, http://purl.org/dc/elements/1.1/creator, "Jack London"") [null]<br>(http://www.franz.com/tutorial#book4, http://purl.org/dc/elements/1.1/title, "White Fang") [null]<br><br>Number of results: 4</pre>
<p>The lesson here is to keep the representation simple. The fewer resources there are, the faster everything will work. </p>
<h3>Don't Create Duplicate Triples</h3>
<p>Now we'll consider the situation where we have multiple copies of the same information in the triple store. This is the classic "duplicate triples" situation. </p>
<p>True duplicate triples do not occur by accident. They occur only when you have loaded the same information into the triple store more than once. </p>
<p>This is easy to demonstrate. Let's load the Kennedy graph into an empty triple store:</p>
<pre class="output">
After loading, there are 1214 kennedy triples.</pre>
<p>Then just load the same file again:</p>
<pre class="output">
After loading, there are 2428 kennedy triples.</pre>
<p>Now there are two copies of every Kennedy triple. If you add the same triple multiple times, you will get multiple copies of it. </p>
<h3 id="DuplicatesAndSparql">Duplicates and SPARQL</h3>
<p>
  The
  SPARQL <a href="https://www.w3.org/TR/sparql11-query/">specification</a>
  assumes that the queried data consists of RDF graphs, which
  are <strong>sets</strong> of triples. This means that, in theory,
  there should be no duplicates in the input data as seen by a SPARQL
  query, although duplicate results might be produced, as we have seen
  already. In practice, filtering out all redundant triples would have
  a very significant negative impact on performance. For this reason
  AllegroGraph will not perform this operation. It will, however,
  hide <strong>some</strong> of the duplicate triples, to avoid
  unnecessarily processing the same data multiple times.</p>

<p>This behavior can lead to some surprising results. For example, the
following SPARQL query:</p>
<pre>
  SELECT count(*) WHERE { ?s ?p ?o }
</pre>
<p>could return either the number of unique triples in the store, the
number of all triples (including duplicates), <strong>or any number in
between</strong>.</p>

<h3>Filter Out Duplicate Results </h3>
<p>In practice, our advice &quot;don't create duplicate triples&quot;
may be difficult to follow. Some data feeds contain duplicated
information and there is no convenient or efficient way to filter it
out. So now you have duplicated data in the system. How much trouble
might that cause?</p>
<p>This simple query should return three matches, one for each of Ted
Kennedy's three children: </p>
<pre class="input">    SELECT ?o WHERE {kdy:person17 kdy:has-child ?o}</pre>
<p>However, because each of the expected triples has a duplicate,
we <a href="#DuplicatesAndSparql">may</a> get up to six answers
instead of three: </p>
<pre class="output">SPARQL matches for children of Ted Kennedy.<br>http://www.franz.com/simple#person72<br>http://www.franz.com/simple#person72<br>http://www.franz.com/simple#person74<br>http://www.franz.com/simple#person74<br>http://www.franz.com/simple#person76<br>http://www.franz.com/simple#person76</pre>
<p>That's a nuisance, but SPARQL provides an easy way to wipe out the duplicate answers: </p>
<pre class="input">    SELECT DISTINCT ?o WHERE {kdy:person17 kdy:has-child ?o}</pre>
<p>The DISTINCT operator does not remove duplicate triples, but it detects and eliminates duplicate variable bindings in the query's output. The duplicate triples are still there in the triple store, but we don't see them in the output:</p>
<pre class="output">SPARQL DISTINCT matches for children of Ted Kennedy.<br>http://www.franz.com/simple#person72<br>http://www.franz.com/simple#person74<br>http://www.franz.com/simple#person76</pre>
<p>DISTINCT works by sorting the bindings by each of the bound variables in the result. This forces duplicate results to be adjacent to each other in the result list. Then it runs over the list and eliminates bindings that are the same as the previous binding. As you can imagine, there are situations where forcing an exhaustive sort on a large binding set might use up a lot of time. </p>
<p>For this reason, SPARQL also offers a REDUCED operator:</p>
<pre class="input">    SELECT REDUCED ?o WHERE {kdy:person17 kdy:has-child ?o} ORDER BY ?o</pre>
<p>REDUCED performs the same sweep for duplicates that DISTINCT
performs, but it does not perform the (potentialy costly) sorting
step. But if the results are already sorted (using ORDER BY), that
will produce the same output that using DISTINCT would. In this
example the values of the subject and predicate are fixed, so sorting
by the object value is sufficient to force all duplicate bindings to
be adjacent to each other. REDUCED is often much faster than
DISTINCT. If the data is not properly sorted, some duplicates might
not be filtered out, but in many applications that is acceptable.</p>

<h3>Filtering Duplicate Triples while Loading </h3>
<p>
  AllegroGraph provides facilities for detecting and removing
  duplicate triples from the store. This can be done in one of two
  ways:</p>
<ol>
  <li>At any point it is possible to explicitly perform a duplicate
  removal operation.</li>
  <li>A store can be configured to suppress duplicates whenever new
    triples are committed.  Note that this will affect only the new
    triples - anything that is already in the store will not be
    deleted.
  </li>
</ol>
<p>Explicit duplicate deletion can be performed by calling the
deleteDuplicates() method of the connection objects, as shown
below:</p>
<pre class="input">
  conn.clear();
  conn.add(new File("src/tutorial/java-kennedy.ntriples"), baseURI, RDFFormat.NTRIPLES);
  conn.add(new File("src/tutorial/java-kennedy.ntriples"), baseURI, RDFFormat.NTRIPLES);
  
  println("Triple count before duplicate deletion: " + conn.size());
  conn.deleteDuplicates("spog");
  println("Triple count after duplicate deletion: " + conn.size());
  </pre>
<pre class="output">
  Triple count before duplicate deletion: 2428
  Triple count after duplicate deletion: 1214
</pre>
<p>The argument to deleteDuplicates() is a string that describes how
to check if two triples should be considered as identical. The allowed
values are "spo" and "spog". The difference is that "spog" will only
detect duplicates in the same graph, while "spo" operates across
graphs.</p>

<p>To enable duplicate suppression at commit time, call
setDuplicateSuppressionPolicy() on the repository object. The argument
has the same meaning as in deleteDuplicates()</p>
<pre class="input">
  myRepository.setDuplicateSuppressionPolicy("spog");
  println("Trying to import the same set of triples a second time.");
  conn.add(new File("src/tutorial/java-kennedy.ntriples"), baseURI, RDFFormat.NTRIPLES);
  println("Triple count after import: " + conn.size());
</pre>
<pre class="output">
  Trying to import the same set of triples a second time.
  Triple count after import: 1214
</pre>
<p><a href="../deleting-duplicate-triples.html">AllegroGraph
documentation contains further information about handling of duplicate
triples.</a></p>

<h3>Duplicates in Federated Stores</h3>
<p>A <a href="#Federated Repositories">federated store</a> is a single connection to multiple AllegroGraph repositories, possibly on multiple servers at multiple sites. Such systems can have duplicate triples, but deleting them is unwise.</p>
<p>Presumably any existing repository has a purpose of its own, and has been federated with other respositories to serve some combined purpose. It would be a mistake to delete triples from one repository simply because they also occur elsewhere in the federated store. This could damage the integrity of the individual repositories when they are used in stand-alone mode. By similar reasoning, it is a mistake to add triples to a federated repository. Which repository gets the new triples? </p>
<p>For all of these reasons, federated stores are "read only" in AllegroGraph. Attempting to add or delete triples in a federated system result in error messages. </p>
<p>Federation changes the semantics of "duplicate triples." Be sure to take this into account in your project design. </p>


</body>
</html>
